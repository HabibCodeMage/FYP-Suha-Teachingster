{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSHhxT26fHMt",
        "outputId": "52f0c254-68c8-4246-bd0f-682cc8d27917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EzDn_UO7y3HM"
      },
      "source": [
        "**Pipeline for Long-Form Question Answering (LFQA)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hSD-TV3yyOn",
        "outputId": "99da5670-ba98-407f-c632-8f918ca6f777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  dataTwo.zip\n",
            "   creating: dataTwo/\n",
            "  inflating: dataTwo/1.txt           \n",
            "  inflating: dataTwo/10.txt          \n",
            "  inflating: dataTwo/100.txt         \n",
            "  inflating: dataTwo/101.txt         \n",
            "  inflating: dataTwo/102.txt         \n",
            "  inflating: dataTwo/103.txt         \n",
            "  inflating: dataTwo/104.txt         \n",
            "  inflating: dataTwo/105.txt         \n",
            "  inflating: dataTwo/106.txt         \n",
            "  inflating: dataTwo/107.txt         \n",
            "  inflating: dataTwo/108.txt         \n",
            "  inflating: dataTwo/109.txt         \n",
            "  inflating: dataTwo/11.txt          \n",
            "  inflating: dataTwo/110.txt         \n",
            "  inflating: dataTwo/111.txt         \n",
            "  inflating: dataTwo/112.txt         \n",
            "  inflating: dataTwo/113.txt         \n",
            "  inflating: dataTwo/114.txt         \n",
            "  inflating: dataTwo/115.txt         \n",
            "  inflating: dataTwo/116.txt         \n",
            "  inflating: dataTwo/117.txt         \n",
            "  inflating: dataTwo/118.txt         \n",
            "  inflating: dataTwo/119.txt         \n",
            "  inflating: dataTwo/12.txt          \n",
            "  inflating: dataTwo/120.txt         \n",
            "  inflating: dataTwo/121.txt         \n",
            "  inflating: dataTwo/122.txt         \n",
            "  inflating: dataTwo/123.txt         \n",
            "  inflating: dataTwo/124.txt         \n",
            "  inflating: dataTwo/125.txt         \n",
            "  inflating: dataTwo/126.txt         \n",
            "  inflating: dataTwo/127.txt         \n",
            "  inflating: dataTwo/128.txt         \n",
            "  inflating: dataTwo/129.txt         \n",
            "  inflating: dataTwo/13.txt          \n",
            "  inflating: dataTwo/130.txt         \n",
            "  inflating: dataTwo/131.txt         \n",
            "  inflating: dataTwo/132.txt         \n",
            "  inflating: dataTwo/133.txt         \n",
            "  inflating: dataTwo/134.txt         \n",
            "  inflating: dataTwo/135.txt         \n",
            "  inflating: dataTwo/136.txt         \n",
            "  inflating: dataTwo/137.txt         \n",
            "  inflating: dataTwo/138.txt         \n",
            "  inflating: dataTwo/139.txt         \n",
            "  inflating: dataTwo/14.txt          \n",
            "  inflating: dataTwo/140.txt         \n",
            "  inflating: dataTwo/141.txt         \n",
            "  inflating: dataTwo/142.txt         \n",
            "  inflating: dataTwo/143.txt         \n",
            "  inflating: dataTwo/144.txt         \n",
            "  inflating: dataTwo/145.txt         \n",
            "  inflating: dataTwo/146.txt         \n",
            "  inflating: dataTwo/147.txt         \n",
            "  inflating: dataTwo/148.txt         \n",
            "  inflating: dataTwo/149.txt         \n",
            "  inflating: dataTwo/15.txt          \n",
            "  inflating: dataTwo/150.txt         \n",
            "  inflating: dataTwo/151.txt         \n",
            "  inflating: dataTwo/152.txt         \n",
            "  inflating: dataTwo/153.txt         \n",
            "  inflating: dataTwo/154.txt         \n",
            "  inflating: dataTwo/155.txt         \n",
            "  inflating: dataTwo/156.txt         \n",
            "  inflating: dataTwo/157.txt         \n",
            "  inflating: dataTwo/158.txt         \n",
            "  inflating: dataTwo/159.txt         \n",
            "  inflating: dataTwo/16.txt          \n",
            "  inflating: dataTwo/160.txt         \n",
            "  inflating: dataTwo/161.txt         \n",
            "  inflating: dataTwo/162.txt         \n",
            "  inflating: dataTwo/163.txt         \n",
            "  inflating: dataTwo/164.txt         \n",
            "  inflating: dataTwo/165.txt         \n",
            "  inflating: dataTwo/166.txt         \n",
            "  inflating: dataTwo/167.txt         \n",
            "  inflating: dataTwo/168.txt         \n",
            "  inflating: dataTwo/169.txt         \n",
            "  inflating: dataTwo/17.txt          \n",
            "  inflating: dataTwo/170.txt         \n",
            "  inflating: dataTwo/171.txt         \n",
            "  inflating: dataTwo/172.txt         \n",
            "  inflating: dataTwo/173.txt         \n",
            "  inflating: dataTwo/174.txt         \n",
            "  inflating: dataTwo/175.txt         \n",
            "  inflating: dataTwo/176.txt         \n",
            "  inflating: dataTwo/177.txt         \n",
            "  inflating: dataTwo/178..txt        \n",
            "  inflating: dataTwo/179.txt         \n",
            "  inflating: dataTwo/18.txt          \n",
            "  inflating: dataTwo/180.txt         \n",
            "  inflating: dataTwo/181.txt         \n",
            "  inflating: dataTwo/182.txt         \n",
            "  inflating: dataTwo/183.txt         \n",
            "  inflating: dataTwo/184.txt         \n",
            "  inflating: dataTwo/185.txt         \n",
            "  inflating: dataTwo/186.txt         \n",
            "  inflating: dataTwo/187.txt         \n",
            "  inflating: dataTwo/188.txt         \n",
            "  inflating: dataTwo/189.txt         \n",
            "  inflating: dataTwo/19.txt          \n",
            "  inflating: dataTwo/190.txt         \n",
            "  inflating: dataTwo/191.txt         \n",
            "  inflating: dataTwo/192.txt         \n",
            "  inflating: dataTwo/193.txt         \n",
            "  inflating: dataTwo/194.txt         \n",
            "  inflating: dataTwo/195.txt         \n",
            "  inflating: dataTwo/196.txt         \n",
            "  inflating: dataTwo/197.txt         \n",
            "  inflating: dataTwo/198.txt         \n",
            "  inflating: dataTwo/199.txt         \n",
            "  inflating: dataTwo/2.txt           \n",
            "  inflating: dataTwo/20.txt          \n",
            "  inflating: dataTwo/200.txt         \n",
            "  inflating: dataTwo/201.txt         \n",
            "  inflating: dataTwo/202.txt         \n",
            "  inflating: dataTwo/203.txt         \n",
            "  inflating: dataTwo/204.txt         \n",
            "  inflating: dataTwo/205.txt         \n",
            "  inflating: dataTwo/206.txt         \n",
            "  inflating: dataTwo/207.txt         \n",
            " extracting: dataTwo/208.txt         \n",
            "  inflating: dataTwo/209.txt         \n",
            "  inflating: dataTwo/21.txt          \n",
            "  inflating: dataTwo/210.txt         \n",
            "  inflating: dataTwo/211.txt         \n",
            "  inflating: dataTwo/212.txt         \n",
            "  inflating: dataTwo/213.txt         \n",
            "  inflating: dataTwo/214.txt         \n",
            "  inflating: dataTwo/215.txt         \n",
            "  inflating: dataTwo/216.txt         \n",
            "  inflating: dataTwo/217.txt         \n",
            "  inflating: dataTwo/218.txt         \n",
            "  inflating: dataTwo/219.txt         \n",
            "  inflating: dataTwo/22.txt          \n",
            "  inflating: dataTwo/220.txt         \n",
            "  inflating: dataTwo/221.txt         \n",
            "  inflating: dataTwo/222.txt         \n",
            "  inflating: dataTwo/223.txt         \n",
            "  inflating: dataTwo/224.txt         \n",
            "  inflating: dataTwo/225.txt         \n",
            "  inflating: dataTwo/226.txt         \n",
            "  inflating: dataTwo/227.txt         \n",
            "  inflating: dataTwo/228.txt         \n",
            "  inflating: dataTwo/229.txt         \n",
            "  inflating: dataTwo/23.txt          \n",
            "  inflating: dataTwo/230.txt         \n",
            "  inflating: dataTwo/231.txt         \n",
            "  inflating: dataTwo/232.txt         \n",
            "  inflating: dataTwo/233.txt         \n",
            "  inflating: dataTwo/234.txt         \n",
            "  inflating: dataTwo/235.txt         \n",
            "  inflating: dataTwo/236.txt         \n",
            "  inflating: dataTwo/237.txt         \n",
            "  inflating: dataTwo/238.txt         \n",
            "  inflating: dataTwo/239.txt         \n",
            "  inflating: dataTwo/24.txt          \n",
            "  inflating: dataTwo/240.txt         \n",
            "  inflating: dataTwo/241.txt         \n",
            "  inflating: dataTwo/242.txt         \n",
            "  inflating: dataTwo/243.txt         \n",
            "  inflating: dataTwo/244.txt         \n",
            "  inflating: dataTwo/245.txt         \n",
            "  inflating: dataTwo/246.txt         \n",
            "  inflating: dataTwo/247.txt         \n",
            "  inflating: dataTwo/248.txt         \n",
            "  inflating: dataTwo/249.txt         \n",
            "  inflating: dataTwo/25.txt          \n",
            "  inflating: dataTwo/250.txt         \n",
            "  inflating: dataTwo/251.txt         \n",
            "  inflating: dataTwo/252.txt         \n",
            "  inflating: dataTwo/253.txt         \n",
            "  inflating: dataTwo/254.txt         \n",
            "  inflating: dataTwo/255.txt         \n",
            "  inflating: dataTwo/256.txt         \n",
            "  inflating: dataTwo/257.txt         \n",
            "  inflating: dataTwo/258.txt         \n",
            "  inflating: dataTwo/259.txt         \n",
            "  inflating: dataTwo/26.txt          \n",
            "  inflating: dataTwo/260.txt         \n",
            "  inflating: dataTwo/261.txt         \n",
            "  inflating: dataTwo/262.txt         \n",
            "  inflating: dataTwo/263.txt         \n",
            "  inflating: dataTwo/264.txt         \n",
            "  inflating: dataTwo/265.txt         \n",
            "  inflating: dataTwo/266.txt         \n",
            "  inflating: dataTwo/267.txt         \n",
            "  inflating: dataTwo/268.txt         \n",
            "  inflating: dataTwo/269.txt         \n",
            "  inflating: dataTwo/27.txt          \n",
            "  inflating: dataTwo/270.txt         \n",
            "  inflating: dataTwo/271.txt         \n",
            "  inflating: dataTwo/272.txt         \n",
            "  inflating: dataTwo/273.txt         \n",
            "  inflating: dataTwo/274.txt         \n",
            "  inflating: dataTwo/275.txt         \n",
            "  inflating: dataTwo/276.txt         \n",
            "  inflating: dataTwo/277.txt         \n",
            "  inflating: dataTwo/278.txt         \n",
            "  inflating: dataTwo/279.txt         \n",
            "  inflating: dataTwo/28.txt          \n",
            "  inflating: dataTwo/29.txt          \n",
            "  inflating: dataTwo/290.txt         \n",
            "  inflating: dataTwo/291.txt         \n",
            "  inflating: dataTwo/292.txt         \n",
            "  inflating: dataTwo/293.txt         \n",
            "  inflating: dataTwo/294.txt         \n",
            "  inflating: dataTwo/295.txt         \n",
            "  inflating: dataTwo/296.txt         \n",
            "  inflating: dataTwo/297.txt         \n",
            "  inflating: dataTwo/298.txt         \n",
            "  inflating: dataTwo/299.txt         \n",
            "  inflating: dataTwo/3.txt           \n",
            "  inflating: dataTwo/30.txt          \n",
            "  inflating: dataTwo/300.txt         \n",
            "  inflating: dataTwo/301.txt         \n",
            "  inflating: dataTwo/302.txt         \n",
            "  inflating: dataTwo/303.txt         \n",
            "  inflating: dataTwo/304.txt         \n",
            "  inflating: dataTwo/305.txt         \n",
            "  inflating: dataTwo/306.txt         \n",
            "  inflating: dataTwo/307.txt         \n",
            "  inflating: dataTwo/308.txt         \n",
            "  inflating: dataTwo/309.txt         \n",
            "  inflating: dataTwo/31.txt          \n",
            "  inflating: dataTwo/310.txt         \n",
            "  inflating: dataTwo/311.txt         \n",
            "  inflating: dataTwo/312.txt         \n",
            "  inflating: dataTwo/313.txt         \n",
            "  inflating: dataTwo/314.txt         \n",
            "  inflating: dataTwo/315.txt         \n",
            "  inflating: dataTwo/316.txt         \n",
            "  inflating: dataTwo/317.txt         \n",
            "  inflating: dataTwo/318.txt         \n",
            "  inflating: dataTwo/319.txt         \n",
            "  inflating: dataTwo/32.txt          \n",
            "  inflating: dataTwo/320.txt         \n",
            "  inflating: dataTwo/321.txt         \n",
            "  inflating: dataTwo/322.txt         \n",
            "  inflating: dataTwo/323.txt         \n",
            "  inflating: dataTwo/324.txt         \n",
            "  inflating: dataTwo/325.txt         \n",
            "  inflating: dataTwo/326.txt         \n",
            "  inflating: dataTwo/327.txt         \n",
            "  inflating: dataTwo/328.txt         \n",
            "  inflating: dataTwo/329.txt         \n",
            "  inflating: dataTwo/33.txt          \n",
            "  inflating: dataTwo/330.txt         \n",
            "  inflating: dataTwo/331.txt         \n",
            "  inflating: dataTwo/332.txt         \n",
            "  inflating: dataTwo/333.txt         \n",
            "  inflating: dataTwo/334.txt         \n",
            "  inflating: dataTwo/335.txt         \n",
            "  inflating: dataTwo/336.txt         \n",
            "  inflating: dataTwo/337.txt         \n",
            "  inflating: dataTwo/338.txt         \n",
            "  inflating: dataTwo/339.txt         \n",
            "  inflating: dataTwo/34.txt          \n",
            "  inflating: dataTwo/340.txt         \n",
            "  inflating: dataTwo/341.txt         \n",
            "  inflating: dataTwo/342.txt         \n",
            "  inflating: dataTwo/343.txt         \n",
            "  inflating: dataTwo/344.txt         \n",
            "  inflating: dataTwo/345.txt         \n",
            "  inflating: dataTwo/346.txt         \n",
            "  inflating: dataTwo/347.txt         \n",
            "  inflating: dataTwo/348.txt         \n",
            "  inflating: dataTwo/349.txt         \n",
            "  inflating: dataTwo/35.txt          \n",
            "  inflating: dataTwo/350.txt         \n",
            "  inflating: dataTwo/351.txt         \n",
            "  inflating: dataTwo/352.txt         \n",
            "  inflating: dataTwo/353.txt         \n",
            "  inflating: dataTwo/354.txt         \n",
            "  inflating: dataTwo/355.txt         \n",
            "  inflating: dataTwo/356.txt         \n",
            "  inflating: dataTwo/357.txt         \n",
            "  inflating: dataTwo/358.txt         \n",
            "  inflating: dataTwo/359.txt         \n",
            "  inflating: dataTwo/36.txt          \n",
            "  inflating: dataTwo/360.txt         \n",
            "  inflating: dataTwo/361.txt         \n",
            "  inflating: dataTwo/362.txt         \n",
            "  inflating: dataTwo/363.txt         \n",
            "  inflating: dataTwo/364.txt         \n",
            "  inflating: dataTwo/365.txt         \n",
            "  inflating: dataTwo/366.txt         \n",
            "  inflating: dataTwo/367.txt         \n",
            "  inflating: dataTwo/368.txt         \n",
            "  inflating: dataTwo/369.txt         \n",
            "  inflating: dataTwo/37.txt          \n",
            "  inflating: dataTwo/370.txt         \n",
            "  inflating: dataTwo/371.txt         \n",
            "  inflating: dataTwo/372.txt         \n",
            "  inflating: dataTwo/373.txt         \n",
            "  inflating: dataTwo/374.txt         \n",
            "  inflating: dataTwo/375.txt         \n",
            "  inflating: dataTwo/376.txt         \n",
            "  inflating: dataTwo/377.txt         \n",
            "  inflating: dataTwo/378.txt         \n",
            "  inflating: dataTwo/379.txt         \n",
            "  inflating: dataTwo/38.txt          \n",
            "  inflating: dataTwo/380.txt         \n",
            "  inflating: dataTwo/381.txt         \n",
            "  inflating: dataTwo/382.txt         \n",
            "  inflating: dataTwo/383.txt         \n",
            "  inflating: dataTwo/384.txt         \n",
            "  inflating: dataTwo/385.txt         \n",
            "  inflating: dataTwo/386.txt         \n",
            "  inflating: dataTwo/387.txt         \n",
            "  inflating: dataTwo/388.txt         \n",
            "  inflating: dataTwo/389.txt         \n",
            "  inflating: dataTwo/39.txt          \n",
            "  inflating: dataTwo/390.txt         \n",
            "  inflating: dataTwo/391.txt         \n",
            "  inflating: dataTwo/392.txt         \n",
            "  inflating: dataTwo/393.txt         \n",
            "  inflating: dataTwo/394.txt         \n",
            "  inflating: dataTwo/395.txt         \n",
            "  inflating: dataTwo/396.txt         \n",
            "  inflating: dataTwo/397.txt         \n",
            "  inflating: dataTwo/398.txt         \n",
            "  inflating: dataTwo/399.txt         \n",
            "  inflating: dataTwo/4.txt           \n",
            "  inflating: dataTwo/40.txt          \n",
            "  inflating: dataTwo/400.txt         \n",
            "  inflating: dataTwo/401.txt         \n",
            "  inflating: dataTwo/402.txt         \n",
            "  inflating: dataTwo/403.txt         \n",
            "  inflating: dataTwo/404.txt         \n",
            "  inflating: dataTwo/405.txt         \n",
            "  inflating: dataTwo/406.txt         \n",
            "  inflating: dataTwo/407.txt         \n",
            "  inflating: dataTwo/408.txt         \n",
            "  inflating: dataTwo/409.txt         \n",
            "  inflating: dataTwo/41.txt          \n",
            "  inflating: dataTwo/410.txt         \n",
            "  inflating: dataTwo/411.txt         \n",
            "  inflating: dataTwo/412.txt         \n",
            "  inflating: dataTwo/413.txt         \n",
            "  inflating: dataTwo/414.txt         \n",
            "  inflating: dataTwo/415.txt         \n",
            "  inflating: dataTwo/416.txt         \n",
            "  inflating: dataTwo/417.txt         \n",
            "  inflating: dataTwo/418.txt         \n",
            "  inflating: dataTwo/419.txt         \n",
            "  inflating: dataTwo/42.txt          \n",
            "  inflating: dataTwo/420.txt         \n",
            "  inflating: dataTwo/421.txt         \n",
            "  inflating: dataTwo/422.txt         \n",
            "  inflating: dataTwo/423.txt         \n",
            "  inflating: dataTwo/424.txt         \n",
            "  inflating: dataTwo/425.txt         \n",
            "  inflating: dataTwo/426.txt         \n",
            "  inflating: dataTwo/427.txt         \n",
            "  inflating: dataTwo/428.txt         \n",
            "  inflating: dataTwo/429.txt         \n",
            "  inflating: dataTwo/43.txt          \n",
            "  inflating: dataTwo/430.txt         \n",
            "  inflating: dataTwo/431.txt         \n",
            "  inflating: dataTwo/432.txt         \n",
            "  inflating: dataTwo/433.txt         \n",
            "  inflating: dataTwo/434.txt         \n",
            "  inflating: dataTwo/435.txt         \n",
            "  inflating: dataTwo/436.txt         \n",
            "  inflating: dataTwo/437.txt         \n",
            "  inflating: dataTwo/438.txt         \n",
            "  inflating: dataTwo/439.txt         \n",
            "  inflating: dataTwo/44.txt          \n",
            "  inflating: dataTwo/440.txt         \n",
            "  inflating: dataTwo/441.txt         \n",
            "  inflating: dataTwo/442.txt         \n",
            "  inflating: dataTwo/443.txt         \n",
            "  inflating: dataTwo/444.txt         \n",
            "  inflating: dataTwo/445.txt         \n",
            "  inflating: dataTwo/446.txt         \n",
            "  inflating: dataTwo/447.txt         \n",
            "  inflating: dataTwo/448.txt         \n",
            "  inflating: dataTwo/449.txt         \n",
            "  inflating: dataTwo/45.txt          \n",
            "  inflating: dataTwo/450.txt         \n",
            "  inflating: dataTwo/451.txt         \n",
            "  inflating: dataTwo/452.txt         \n",
            "  inflating: dataTwo/453.txt         \n",
            "  inflating: dataTwo/454.txt         \n",
            "  inflating: dataTwo/455.txt         \n",
            "  inflating: dataTwo/456.txt         \n",
            "  inflating: dataTwo/457.txt         \n",
            "  inflating: dataTwo/458.txt         \n",
            "  inflating: dataTwo/459.txt         \n",
            "  inflating: dataTwo/46.txt          \n",
            "  inflating: dataTwo/460.txt         \n",
            "  inflating: dataTwo/461.txt         \n",
            "  inflating: dataTwo/462.txt         \n",
            "  inflating: dataTwo/463.txt         \n",
            "  inflating: dataTwo/464.txt         \n",
            "  inflating: dataTwo/465.txt         \n",
            "  inflating: dataTwo/466.txt         \n",
            "  inflating: dataTwo/467.txt         \n",
            "  inflating: dataTwo/468.txt         \n",
            "  inflating: dataTwo/469.txt         \n",
            "  inflating: dataTwo/47.txt          \n",
            "  inflating: dataTwo/470.txt         \n",
            "  inflating: dataTwo/471.txt         \n",
            "  inflating: dataTwo/472.txt         \n",
            "  inflating: dataTwo/473.txt         \n",
            "  inflating: dataTwo/474.txt         \n",
            "  inflating: dataTwo/475.txt         \n",
            "  inflating: dataTwo/476.txt         \n",
            "  inflating: dataTwo/477.txt         \n",
            "  inflating: dataTwo/478.txt         \n",
            "  inflating: dataTwo/479.txt         \n",
            "  inflating: dataTwo/48.txt          \n",
            "  inflating: dataTwo/480.txt         \n",
            "  inflating: dataTwo/481.txt         \n",
            "  inflating: dataTwo/482.txt         \n",
            "  inflating: dataTwo/483.txt         \n",
            "  inflating: dataTwo/484.txt         \n",
            "  inflating: dataTwo/485.txt         \n",
            "  inflating: dataTwo/486.txt         \n",
            "  inflating: dataTwo/487.txt         \n",
            "  inflating: dataTwo/488.txt         \n",
            "  inflating: dataTwo/489.txt         \n",
            "  inflating: dataTwo/49.txt          \n",
            "  inflating: dataTwo/490.txt         \n",
            "  inflating: dataTwo/491.txt         \n",
            "  inflating: dataTwo/492.txt         \n",
            "  inflating: dataTwo/493.txt         \n",
            "  inflating: dataTwo/494.txt         \n",
            "  inflating: dataTwo/495.txt         \n",
            "  inflating: dataTwo/496.txt         \n",
            "  inflating: dataTwo/497.txt         \n",
            "  inflating: dataTwo/498.txt         \n",
            "  inflating: dataTwo/499.txt         \n",
            "  inflating: dataTwo/5.txt           \n",
            "  inflating: dataTwo/50.txt          \n",
            "  inflating: dataTwo/500.txt         \n",
            "  inflating: dataTwo/501.txt         \n",
            "  inflating: dataTwo/502.txt         \n",
            "  inflating: dataTwo/503.txt         \n",
            "  inflating: dataTwo/504.txt         \n",
            "  inflating: dataTwo/505.txt         \n",
            "  inflating: dataTwo/506.txt         \n",
            "  inflating: dataTwo/507.txt         \n",
            "  inflating: dataTwo/508.txt         \n",
            "  inflating: dataTwo/509.txt         \n",
            "  inflating: dataTwo/51.txt          \n",
            "  inflating: dataTwo/510.txt         \n",
            "  inflating: dataTwo/511.txt         \n",
            "  inflating: dataTwo/512.txt         \n",
            "  inflating: dataTwo/513.txt         \n",
            "  inflating: dataTwo/514.txt         \n",
            "  inflating: dataTwo/515.txt         \n",
            "  inflating: dataTwo/516.txt         \n",
            "  inflating: dataTwo/517.txt         \n",
            "  inflating: dataTwo/518.txt         \n",
            "  inflating: dataTwo/519.txt         \n",
            "  inflating: dataTwo/52.txt          \n",
            "  inflating: dataTwo/520.txt         \n",
            "  inflating: dataTwo/521.txt         \n",
            "  inflating: dataTwo/522.txt         \n",
            "  inflating: dataTwo/523.txt         \n",
            "  inflating: dataTwo/524.txt         \n",
            "  inflating: dataTwo/525.txt         \n",
            "  inflating: dataTwo/526.txt         \n",
            "  inflating: dataTwo/527.txt         \n",
            "  inflating: dataTwo/528.txt         \n",
            "  inflating: dataTwo/529.txt         \n",
            "  inflating: dataTwo/53.txt          \n",
            "  inflating: dataTwo/530.txt         \n",
            "  inflating: dataTwo/531.txt         \n",
            "  inflating: dataTwo/532.txt         \n",
            "  inflating: dataTwo/533.txt         \n",
            "  inflating: dataTwo/534.txt         \n",
            "  inflating: dataTwo/535.txt         \n",
            "  inflating: dataTwo/536.txt         \n",
            "  inflating: dataTwo/537.txt         \n",
            "  inflating: dataTwo/538.txt         \n",
            "  inflating: dataTwo/539.txt         \n",
            "  inflating: dataTwo/54.txt          \n",
            "  inflating: dataTwo/540.txt         \n",
            "  inflating: dataTwo/541.txt         \n",
            "  inflating: dataTwo/542.txt         \n",
            "  inflating: dataTwo/543.txt         \n",
            "  inflating: dataTwo/544.txt         \n",
            "  inflating: dataTwo/545.txt         \n",
            "  inflating: dataTwo/546.txt         \n",
            "  inflating: dataTwo/547.txt         \n",
            "  inflating: dataTwo/548.txt         \n",
            "  inflating: dataTwo/549.txt         \n",
            "  inflating: dataTwo/55.txt          \n",
            "  inflating: dataTwo/550.txt         \n",
            "  inflating: dataTwo/551.txt         \n",
            "  inflating: dataTwo/552.txt         \n",
            "  inflating: dataTwo/553.txt         \n",
            "  inflating: dataTwo/554.txt         \n",
            "  inflating: dataTwo/555.txt         \n",
            "  inflating: dataTwo/556.txt         \n",
            "  inflating: dataTwo/557.txt         \n",
            "  inflating: dataTwo/558.txt         \n",
            "  inflating: dataTwo/559.txt         \n",
            "  inflating: dataTwo/56.txt          \n",
            "  inflating: dataTwo/560.txt         \n",
            "  inflating: dataTwo/561.txt         \n",
            "  inflating: dataTwo/562.txt         \n",
            "  inflating: dataTwo/563.txt         \n",
            "  inflating: dataTwo/564.txt         \n",
            "  inflating: dataTwo/565.txt         \n",
            "  inflating: dataTwo/566.txt         \n",
            "  inflating: dataTwo/567.txt         \n",
            "  inflating: dataTwo/568.txt         \n",
            "  inflating: dataTwo/569.txt         \n",
            "  inflating: dataTwo/57.txt          \n",
            "  inflating: dataTwo/570.txt         \n",
            "  inflating: dataTwo/571.txt         \n",
            "  inflating: dataTwo/572.txt         \n",
            "  inflating: dataTwo/573.txt         \n",
            "  inflating: dataTwo/574.txt         \n",
            "  inflating: dataTwo/575.txt         \n",
            " extracting: dataTwo/576.txt         \n",
            "  inflating: dataTwo/58.txt          \n",
            "  inflating: dataTwo/59.txt          \n",
            "  inflating: dataTwo/6.txt           \n",
            "  inflating: dataTwo/60.txt          \n",
            "  inflating: dataTwo/61.txt          \n",
            "  inflating: dataTwo/62.txt          \n",
            "  inflating: dataTwo/63.txt          \n",
            "  inflating: dataTwo/64.txt          \n",
            "  inflating: dataTwo/65.txt          \n",
            "  inflating: dataTwo/66.txt          \n",
            "  inflating: dataTwo/67.txt          \n",
            "  inflating: dataTwo/68.txt          \n",
            "  inflating: dataTwo/69.txt          \n",
            "  inflating: dataTwo/7.txt           \n",
            "  inflating: dataTwo/70.txt          \n",
            "  inflating: dataTwo/71.txt          \n",
            "  inflating: dataTwo/72.txt          \n",
            "  inflating: dataTwo/73.txt          \n",
            "  inflating: dataTwo/74.txt          \n",
            "  inflating: dataTwo/75.txt          \n",
            "  inflating: dataTwo/76.txt          \n",
            "  inflating: dataTwo/77.txt          \n",
            "  inflating: dataTwo/78.txt          \n",
            "  inflating: dataTwo/79.txt          \n",
            "  inflating: dataTwo/8.txt           \n",
            "  inflating: dataTwo/80.txt          \n",
            "  inflating: dataTwo/81.txt          \n",
            "  inflating: dataTwo/82.txt          \n",
            "  inflating: dataTwo/83.txt          \n",
            "  inflating: dataTwo/84.txt          \n",
            "  inflating: dataTwo/85.txt          \n",
            "  inflating: dataTwo/86.txt          \n",
            "  inflating: dataTwo/87.txt          \n",
            "  inflating: dataTwo/88.txt          \n",
            "  inflating: dataTwo/89.txt          \n",
            "  inflating: dataTwo/9.txt           \n",
            "  inflating: dataTwo/90.txt          \n",
            "  inflating: dataTwo/91.txt          \n",
            "  inflating: dataTwo/92.txt          \n",
            "  inflating: dataTwo/93.txt          \n",
            "  inflating: dataTwo/94.txt          \n",
            "  inflating: dataTwo/95.txt          \n",
            "  inflating: dataTwo/96.txt          \n",
            "  inflating: dataTwo/97.txt          \n",
            "  inflating: dataTwo/98.txt          \n",
            "  inflating: dataTwo/99.txt          \n"
          ]
        }
      ],
      "source": [
        "!unzip dataTwo.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caYaFEtrzfZy",
        "outputId": "be01c32f-edf7-4a06-e047-a5b0aca90243"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting farm-haystack[colab,faiss]\n",
            "  Cloning https://github.com/deepset-ai/haystack.git to /tmp/pip-install-r3xb5fne/farm-haystack_9c4ce934e8f648aea420170c239de375\n",
            "  Resolved https://github.com/deepset-ai/haystack.git to commit b353b22fffb6d4abd7f478966b3e085a369abab9\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting azure-ai-formrecognizer>=3.2.0b2 (from farm-haystack[colab,faiss])\n",
            "  Downloading azure_ai_formrecognizer-3.3.0b1-py3-none-any.whl (299 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 299.9/299.9 kB 14.9 MB/s eta 0:00:00\n",
            "Collecting boilerpy3 (from farm-haystack[colab,faiss])\n",
            "  Downloading boilerpy3-1.0.6-py3-none-any.whl (22 kB)\n",
            "Collecting canals==0.2.2 (from farm-haystack[colab,faiss])\n",
            "  Downloading canals-0.2.2-py3-none-any.whl (31 kB)\n",
            "Collecting dill (from farm-haystack[colab,faiss])\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 13.9 MB/s eta 0:00:00\n",
            "Collecting events (from farm-haystack[colab,faiss])\n",
            "  Downloading Events-0.4.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting generalimport (from farm-haystack[colab,faiss])\n",
            "  Downloading generalimport-0.3.1-py3-none-any.whl (21 kB)\n",
            "Collecting huggingface-hub>=0.5.0 (from farm-haystack[colab,faiss])\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 224.5/224.5 kB 27.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,faiss]) (4.3.3)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,faiss]) (9.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,faiss]) (3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,faiss]) (1.5.3)\n",
            "Collecting posthog (from farm-haystack[colab,faiss])\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Collecting protobuf<=3.20.2 (from farm-haystack[colab,faiss])\n",
            "  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 62.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,faiss]) (1.10.7)\n",
            "Collecting quantulum3 (from farm-haystack[colab,faiss])\n",
            "  Downloading quantulum3-0.9.0-py3-none-any.whl (10.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.7/10.7 MB 111.2 MB/s eta 0:00:00\n",
            "Collecting rank-bm25 (from farm-haystack[colab,faiss])\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,faiss]) (2.27.1)\n",
            "Collecting requests-cache<1.0.0 (from farm-haystack[colab,faiss])\n",
            "  Downloading requests_cache-0.9.8-py3-none-any.whl (48 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.7/48.7 kB 5.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,faiss]) (1.2.2)\n",
            "Collecting sentence-transformers>=2.2.0 (from farm-haystack[colab,faiss])\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.0/86.0 kB 11.0 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting sseclient-py (from farm-haystack[colab,faiss])\n",
            "  Downloading sseclient_py-1.7.2-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,faiss]) (8.2.2)\n",
            "Collecting tiktoken>=0.3.2 (from farm-haystack[colab,faiss])\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 83.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,faiss]) (4.65.0)\n",
            "Collecting transformers[torch]==4.29.1 (from farm-haystack[colab,faiss])\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.1/7.1 MB 111.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pillow<=9.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,faiss]) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[torch]==4.29.1->farm-haystack[colab,faiss])\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 119.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (2.0.1+cu118)\n",
            "Collecting accelerate>=0.19.0 (from transformers[torch]==4.29.1->farm-haystack[colab,faiss])\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 219.1/219.1 kB 25.0 MB/s eta 0:00:00\n",
            "Collecting azure-core<2.0.0,>=1.23.0 (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,faiss])\n",
            "  Downloading azure_core-1.26.4-py3-none-any.whl (173 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 173.9/173.9 kB 19.0 MB/s eta 0:00:00\n",
            "Collecting msrest>=0.6.21 (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,faiss])\n",
            "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.4/85.4 kB 10.3 MB/s eta 0:00:00\n",
            "Collecting azure-common~=1.1 (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,faiss])\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,faiss]) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.5.0->farm-haystack[colab,faiss]) (2023.4.0)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,faiss]) (1.4.4)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,faiss]) (23.1.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache<1.0.0->farm-haystack[colab,faiss])\n",
            "  Downloading cattrs-22.2.0-py3-none-any.whl (35 kB)\n",
            "Collecting url-normalize>=1.4 (from requests-cache<1.0.0->farm-haystack[colab,faiss])\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.5 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,faiss]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,faiss]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,faiss]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,faiss]) (3.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->farm-haystack[colab,faiss]) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->farm-haystack[colab,faiss]) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->farm-haystack[colab,faiss]) (3.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.0->farm-haystack[colab,faiss]) (0.15.2+cu118)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.0->farm-haystack[colab,faiss]) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers>=2.2.0->farm-haystack[colab,faiss])\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 78.1 MB/s eta 0:00:00\n",
            "Collecting psycopg2-binary (from farm-haystack[colab,faiss])\n",
            "  Downloading psycopg2_binary-2.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 105.6 MB/s eta 0:00:00\n",
            "Collecting sqlalchemy-utils (from farm-haystack[colab,faiss])\n",
            "  Downloading SQLAlchemy_Utils-0.41.1-py3-none-any.whl (92 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.6/92.6 kB 13.1 MB/s eta 0:00:00\n",
            "Collecting sqlalchemy<2,>=1.4.2 (from farm-haystack[colab,faiss])\n",
            "  Downloading SQLAlchemy-1.4.48-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 82.2 MB/s eta 0:00:00\n",
            "Collecting faiss-cpu<=1.7.2,>=1.6.3 (from farm-haystack[colab,faiss])\n",
            "  Downloading faiss_cpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 121.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,faiss]) (0.19.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab,faiss]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab,faiss]) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab,faiss]) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->farm-haystack[colab,faiss])\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->farm-haystack[colab,faiss])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[colab,faiss]) (6.0.4)\n",
            "Collecting num2words (from quantulum3->farm-haystack[colab,faiss])\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.2/125.2 kB 16.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (5.9.5)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[colab,faiss]) (1.1.1)\n",
            "Collecting isodate>=0.6.0 (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,faiss])\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.7/41.7 kB 5.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,faiss]) (1.3.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2,>=1.4.2->farm-haystack[colab,faiss]) (2.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (16.0.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=2.2.0->farm-haystack[colab,faiss]) (8.1.3)\n",
            "Collecting docopt>=0.6.2 (from num2words->quantulum3->farm-haystack[colab,faiss])\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,faiss]) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]==4.29.1->farm-haystack[colab,faiss]) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers, events, farm-haystack, docopt\n",
            "  Building wheel for sentence-transformers (setup.py): started\n",
            "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=ee7976538c98b58b8c594b93c342199c502c89f76aaf3680da70adc5f02447a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for events (setup.py): started\n",
            "  Building wheel for events (setup.py): finished with status 'done'\n",
            "  Created wheel for events: filename=Events-0.4-py3-none-any.whl size=6273 sha256=54b5aedc7c57bc52c990f1bbed8c0f7c499e857ed2ff7e0b088bb12f5103f671\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/34/cf/445b39702c5a25aa8ceccf99429f5855726be49d43ce31ec03\n",
            "  Building wheel for farm-haystack (pyproject.toml): started\n",
            "  Building wheel for farm-haystack (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for farm-haystack: filename=farm_haystack-1.18.0rc0-py3-none-any.whl size=721598 sha256=84b2d0bb0c95dcae4fbfd5bdc445d90fa8235535a3f728c07a67024e5ac344ec\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bjli3uhp/wheels/e7/f8/df/e7c3a1fea47ea9a9db18c056e698a82658e0fe5814c5608165\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=f17c0f19a5e31bd95dae1185f73268b425513debff0d4335e42a5508152fbf86\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built sentence-transformers events farm-haystack docopt\n",
            "Installing collected packages: tokenizers, sseclient-py, sentencepiece, monotonic, generalimport, faiss-cpu, events, docopt, azure-common, url-normalize, sqlalchemy, rank-bm25, psycopg2-binary, protobuf, num2words, isodate, dill, cattrs, canals, boilerpy3, backoff, tiktoken, sqlalchemy-utils, requests-cache, posthog, huggingface-hub, azure-core, transformers, quantulum3, msrest, azure-ai-formrecognizer, accelerate, sentence-transformers, farm-haystack\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.10\n",
            "    Uninstalling SQLAlchemy-2.0.10:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.10\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "Successfully installed accelerate-0.19.0 azure-ai-formrecognizer-3.3.0b1 azure-common-1.1.28 azure-core-1.26.4 backoff-2.2.1 boilerpy3-1.0.6 canals-0.2.2 cattrs-22.2.0 dill-0.3.6 docopt-0.6.2 events-0.4 faiss-cpu-1.7.2 farm-haystack-1.18.0rc0 generalimport-0.3.1 huggingface-hub-0.14.1 isodate-0.6.1 monotonic-1.6 msrest-0.7.1 num2words-0.5.12 posthog-3.0.1 protobuf-3.20.2 psycopg2-binary-2.9.6 quantulum3-0.9.0 rank-bm25-0.2.2 requests-cache-0.9.8 sentence-transformers-2.2.2 sentencepiece-0.1.99 sqlalchemy-1.4.48 sqlalchemy-utils-0.41.1 sseclient-py-1.7.2 tiktoken-0.4.0 tokenizers-0.13.3 transformers-4.29.1 url-normalize-1.4.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEPRECATION: git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab,faiss] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepset-ai/haystack.git /tmp/pip-install-r3xb5fne/farm-haystack_9c4ce934e8f648aea420170c239de375\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab,faiss]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EIUvCSa4ziTy"
      },
      "source": [
        "## Logging\n",
        "\n",
        "We configure how logging messages should be displayed and which log level should be used before importing Haystack.\n",
        "Example log message:\n",
        "INFO - haystack.utils.preprocessing -  Converting data/tutorial1/218_Olenna_Tyrell.txt\n",
        "Default log level in basicConfig is WARNING so the explicit parameter is not necessary but can be changed easily:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNxQqRutzhrI"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e6ju3SLzzrhR"
      },
      "source": [
        "### Document Store\n",
        "\n",
        "FAISS is a library for efficient similarity search on a cluster of dense vectors.\n",
        "The `FAISSDocumentStore` uses a SQL(SQLite in-memory be default) database under-the-hood\n",
        "to store the document text and other meta data. The vector embeddings of the text are\n",
        "indexed on a FAISS Index that later is queried for searching answers.\n",
        "The default flavour of FAISSDocumentStore is \"Flat\" but can also be set to \"HNSW\" for\n",
        "faster search at the expense of some accuracy. Just set the faiss_index_factor_str argument in the constructor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1mXOnl3zoNU",
        "outputId": "f908cd65-f790-4208-e785-5830bd3b9808"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.telemetry:Haystack sends anonymous usage data to understand the actual usage and steer dev efforts towards features that are most meaningful to users. You can opt-out at anytime by manually setting the environment variable HAYSTACK_TELEMETRY_ENABLED as described for different operating systems in the [documentation page](https://docs.haystack.deepset.ai/docs/telemetry#how-can-i-opt-out). More information at [Telemetry](https://docs.haystack.deepset.ai/docs/telemetry).\n"
          ]
        }
      ],
      "source": [
        "from haystack.document_stores import FAISSDocumentStore\n",
        "\n",
        "document_store = FAISSDocumentStore(embedding_dim=768, faiss_index_factory_str=\"Flat\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TMaXPC_7zyEA"
      },
      "source": [
        "### Cleaning & indexing documents\n",
        "\n",
        "we  convert and index documents to our DocumentStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dce026d29fd641238e68874e212967b0",
            "35268d0559da479ab9cabc1fb0d1fa23",
            "87d0d70f1771484180ac07b4f195beb4",
            "b1a0da4373714e38b2cb5c8c8f661234",
            "29a661326dde484a87f0aed0c32fd4ef",
            "1f7e100890c84a628a18e1891a5f9ceb",
            "55a80a8189c34bcc802e0c8a7502553f",
            "7903bcb0423f4894a881a813d04cb4b7",
            "ab47b32b6ffd48e7afbf66f8d2688454",
            "4902b799f8ac42d5b46331dd42fa4c8e",
            "e078f6afac6d48699389845eeda6b1f5"
          ]
        },
        "id": "_qqXKor5z-g0",
        "outputId": "ec229319-bfa8-4c6a-ecfd-55c802545cd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/17.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/466.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/303.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/433.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/183.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/238.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/23.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/148.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/47.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/268.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/248.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/272.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/3.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/126.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/413.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/94.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/116.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/195.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/160.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/567.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/250.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/394.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/536.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/62.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/510.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/158.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/199.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/9.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/304.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/212.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/58.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/197.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/232.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/267.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/477.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/153.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/85.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/245.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/229.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/154.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/415.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/390.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/66.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/290.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/271.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/21.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/319.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/425.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/468.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/196.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/471.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/100.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/88.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/114.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/46.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/395.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/344.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/52.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/573.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/382.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/278.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/368.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/44.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/33.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/6.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/87.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/339.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/190.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/512.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/84.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/63.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/452.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/494.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/572.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/402.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/553.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/186.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/460.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/335.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/273.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/473.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/464.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/431.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/496.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/132.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/332.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/552.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/545.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/305.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/302.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/428.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/168.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/270.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/403.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/231.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/484.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/276.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/60.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/45.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/482.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/334.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/292.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/451.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/90.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/474.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/511.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/12.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/559.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/441.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/333.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/172.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/127.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/503.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/420.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/291.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/329.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/525.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/529.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/8.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/562.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/95.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/307.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/25.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/48.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/39.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/355.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/516.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/106.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/72.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/53.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/251.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/528.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/465.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/247.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/309.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/234.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/371.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/467.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/301.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/570.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/342.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/266.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/297.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/313.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/241.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/109.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/374.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/256.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/210.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/436.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/364.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/554.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/346.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/518.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/448.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/551.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/4.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/224.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/13.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/444.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/36.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/318.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/489.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/341.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/524.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/279.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/558.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/175.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/193.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/38.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/14.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/97.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/205.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/261.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/243.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/30.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/429.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/5.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/277.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/252.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/377.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/162.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/182.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/388.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/56.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/547.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/322.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/520.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/141.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/308.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/370.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/163.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/575.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/472.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/178..txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/71.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/442.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/223.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/363.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/316.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/326.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/311.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/80.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/356.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/111.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/108.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/138.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/65.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/314.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/165.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/347.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/124.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/15.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/228.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/208.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/550.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/216.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/227.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/317.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/366.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/146.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/187.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/389.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/161.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/198.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/59.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/139.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/571.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/83.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/488.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/378.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/515.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/532.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/424.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/361.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/414.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/539.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/504.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/400.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/439.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/445.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/457.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/298.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/67.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/456.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/73.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/461.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/432.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/61.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/28.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/101.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/194.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/54.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/107.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/300.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/207.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/164.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/566.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/555.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/576.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/360.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/262.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/418.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/55.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/486.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/383.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/217.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/502.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/2.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/565.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/362.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/549.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/561.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/69.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/240.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/497.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/143.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/537.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/421.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/438.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/201.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/104.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/50.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/345.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/89.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/181.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/563.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/218.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/1.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/479.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/476.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/372.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/43.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/221.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/296.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/412.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/507.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/499.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/349.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/359.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/447.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/174.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/373.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/202.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/315.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/385.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/384.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/427.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/105.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/530.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/31.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/246.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/112.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/462.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/230.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/527.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/110.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/404.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/354.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/386.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/426.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/130.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/151.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/206.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/531.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/157.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/564.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/376.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/264.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/446.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/330.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/145.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/191.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/133.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/491.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/405.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/455.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/51.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/411.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/375.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/169.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/27.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/392.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/7.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/353.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/556.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/498.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/259.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/500.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/417.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/480.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/487.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/167.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/64.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/215.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/226.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/440.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/505.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/18.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/179.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/26.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/77.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/340.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/204.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/269.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/379.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/275.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/49.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/147.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/506.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/113.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/74.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/150.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/369.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/526.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/103.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/96.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/140.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/423.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/211.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/274.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/560.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/121.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/548.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/260.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/295.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/233.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/574.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/214.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/119.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/118.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/219.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/99.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/483.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/490.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/42.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/235.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/535.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/380.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/225.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/396.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/454.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/135.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/10.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/327.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/258.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/365.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/320.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/102.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/568.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/348.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/20.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/79.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/189.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/239.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/159.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/222.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/495.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/449.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/306.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/70.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/350.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/569.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/115.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/213.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/435.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/185.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/310.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/501.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/401.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/91.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/393.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/324.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/493.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/541.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/93.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/544.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/343.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/294.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/410.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/450.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/533.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/492.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/534.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/351.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/357.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/416.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/242.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/129.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/120.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/557.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/299.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/128.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/338.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/173.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/521.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/514.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/478.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/76.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/35.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/192.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/68.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/255.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/434.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/37.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/323.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/92.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/244.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/155.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/430.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/188.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/407.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/122.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/508.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/29.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/358.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/11.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/41.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/209.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/463.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/419.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/75.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/443.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/156.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/381.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/137.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/22.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/265.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/82.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/543.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/81.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/321.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/24.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/257.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/263.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/254.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/331.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/469.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/367.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/57.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/149.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/180.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/337.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/142.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/509.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/397.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/98.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/513.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/328.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/312.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/136.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/406.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/184.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/336.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/200.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/519.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/538.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/34.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/398.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/203.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/391.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/123.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/249.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/481.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/475.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/19.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/32.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/166.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/325.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/387.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/409.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/16.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/253.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/542.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/459.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/458.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/540.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/125.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/408.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/171.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/517.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/293.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/437.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/176.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/470.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/453.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/523.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/352.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/144.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/522.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/546.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/78.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/485.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/134.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/131.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/177.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/236.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/152.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/86.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/170.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/220.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/399.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/40.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/422.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/117.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/dataTwo/237.txt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dce026d29fd641238e68874e212967b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Writing Documents:   0%|          | 0/564 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from haystack.utils import convert_files_to_docs, fetch_archive_from_http, clean_wiki_text\n",
        "\n",
        "\n",
        "# Let's first get some files that we want to use\n",
        "doc_dir = \"/content/dataTwo\"\n",
        "# Convert files to dicts\n",
        "docs = convert_files_to_docs(dir_path=doc_dir, clean_func=clean_wiki_text, split_paragraphs=True)\n",
        "\n",
        "# Now, let's write the dicts containing documents to our DB.\n",
        "document_store.write_documents(docs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AkFeNinR0EqV"
      },
      "source": [
        "### Initialize Retriever and Reader/Generator\n",
        "\n",
        "#### Retriever\n",
        "\n",
        "We use a `DensePassageRetriever` and we invoke `update_embeddings` to index the embeddings of documents in the `FAISSDocumentStore`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQ7BC1fq0FdD"
      },
      "outputs": [],
      "source": [
        "save_dir=\"/content/drive/MyDrive/dpr\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "d0ad2b6d0a0c4d789096e74a74464b8e",
            "3f8c320f64fc4ab49039ebf4b05ff6a9",
            "933301643614489491049a7321c1f21b",
            "ef218077ba034925820302c3ff1555a8",
            "6e96d355eeb8421bb1d516ddcdc1a30e",
            "ebdbf0bda0a449efa1b8e25e5a6c2e24",
            "7d127733685f4e809c20d173e8a33410",
            "7e6ea5b7071e44559dd28c553933836e",
            "41c4c4e4174e4b71a6894a8b7a0eddcc",
            "d4178e9222424938ae4ead0257dbe428",
            "7a387068e6d04aa899d7ab8bbfb79e9d",
            "a80e4ea3e02e415b949dec98491752c9",
            "80629454eda5411dba33eae220deb9eb",
            "e99c71c0d8f44d0883e5ce7163265c6e",
            "546a7ce8676e4e0e84029089167ce9ed",
            "6cba0dba212f4f58b139fab291c1e875",
            "df4418e5b5ef4003b5de0517dedfa161",
            "ea5b1f86c869400abbe8f4db65878108",
            "61acccd4965d4107baddacd81663d2a9",
            "a6ae71ac51fb4039bdf14a180b2428f0",
            "6f5b52393f524682a4f4fdbdd8ede356",
            "f7ec2b971ea040bc970f81caffcc94df"
          ]
        },
        "id": "_vtuu2tM0He5",
        "outputId": "18b5f454-6cb3-4d63-ec62-8b9321ef7cb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "INFO:haystack.nodes.retriever.dense:DPR model loaded from /content/drive/MyDrive/dpr\n",
            "INFO:haystack.document_stores.faiss:Updating embeddings for 562 docs...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0ad2b6d0a0c4d789096e74a74464b8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Updating Embedding:   0%|          | 0/562 [00:00<?, ? docs/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a80e4ea3e02e415b949dec98491752c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Create embeddings:   0%|          | 0/576 [00:00<?, ? Docs/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from haystack.nodes import DensePassageRetriever\n",
        "\n",
        "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store)\n",
        "\n",
        "document_store.update_embeddings(retriever)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mKiKgc-r0QcY"
      },
      "source": [
        "Before we blindly use the `DensePassageRetriever` let's empirically test it to make sure a simple search indeed finds the relevant documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q0FiT1E0LJ1",
        "outputId": "4e5b6fcb-2f7d-490d-c7e3-db9a26bc5620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query: what is self join?\n",
            "\n",
            "{   'content': 'self join is used to join a table with itself. it\\n'\n",
            "               'is used when the table has a foreign key that\\n'\n",
            "               'references its own primary key.\\n'\n",
            "               'cross join is used to combine each row from one\\n'\n",
            "               'table with every row from another table. it is\\n'\n",
            "               'also known as a cartesian join. the syntax of\\n'\n",
            "               'natural join is used to combine two tables based\\n'\n",
            "               'on columns that have the same name and data type.\\n'\n",
            "               'conclusion join operation is one of the most\\n'\n",
            "               'important operations in dbms. it is used to\\n'\n",
            "               'combine data from multiple tables and retrieve the\\n'\n",
            "               'requ...',\n",
            "    'name': '187.txt'}\n",
            "\n",
            "{   'content': 'a self join is used to join a table with itself.\\n'\n",
            "               'this join can be performed using table aliases,\\n'\n",
            "               'which allow us to avoid repeating the same table\\n'\n",
            "               'name in a single sentence. it will throw an error\\n'\n",
            "               'if we use the same table name more than once in a\\n'\n",
            "               'single query without using table aliases.',\n",
            "    'name': '513.txt'}\n",
            "\n",
            "{   'content': 'join operation in dbms introduction in dbms, a\\n'\n",
            "               'join operation is used to combine two or more\\n'\n",
            "               'tables based on a common column. this operation is\\n'\n",
            "               'important for querying data from multiple tables\\n'\n",
            "               'and retrieving the required information. join\\n'\n",
            "               'operation is used to combine rows from two or more\\n'\n",
            "               'tables into a single table based on a related\\n'\n",
            "               'Different types of joins are inner join,outer join,left outer '\n",
            "               'join,right outer\\n'\n",
            "               'join,full outer join, self join, cross join , natural\\n'\n",
            "               'inner join is the most commonly\\n'\n",
            "               'used join o...',\n",
            "    'name': '47.txt'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from haystack.utils import print_documents\n",
        "from haystack.pipelines import DocumentSearchPipeline\n",
        "\n",
        "p_retrieval = DocumentSearchPipeline(retriever)\n",
        "res = p_retrieval.run(query=\"what is self join?\", params={\"Retriever\": {\"top_k\": 3}})\n",
        "print_documents(res, max_text_len=512)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yjLxsIF-0V0p"
      },
      "source": [
        "#### Reader/Generator\n",
        "\n",
        "we now initalize our reader/generator.\n",
        "\n",
        "Here we use a `Seq2SeqGenerator` with the bart_lfqa* model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "f97bd054fbfd4c0fad33ddc80b3d2488",
            "4603e6d588084a3ba0c9c1af22c3731a",
            "5a3d878701bb495aaca15abf55796219",
            "6b9b36b8a51c46d8b3c98b12d4d827cf",
            "063f1cad4e6f41acb45af775e7abe88b",
            "7a38eb5f11b54fb08833fb87840f0dfa",
            "edfbb8f74e6d4084845cb2e3bb2c08e1",
            "4bc74ab0946f40a59b59509ac8687ce8",
            "88ef52bc389b4663a4d921992e1de9e7",
            "a35741a09a85457ab57ad42200907ece",
            "dab737d05f944c8ab1657dbb9a35c1f5",
            "a42dd6abccc6401cbda13fd7f9c352f8",
            "b04e7275f83349eb94fd43c903fbed69",
            "ea240d452bd74dc7932c1d247cfc05ab",
            "54f51eb21f6d4984b7796dd98a32062c",
            "873d627546e94c9ca1e013e63f92e82e",
            "ae43785c32ed4ad0be76d48069617525",
            "0e65c942399b44e9b46a10ba9d12e0e7",
            "8faa307374634a07b11134ac192e7f6d",
            "1fb812361e814897b94a7a4475ca0df9",
            "4e7165cf02d349a8b73bd3f03a9533ec",
            "cea05cffda68456a9159f02d1701f921",
            "e1660868c5724a2a83391f1b69f5a494",
            "9674f85bbae1480d9c2dfd40d797a161",
            "ce89fd68cb214726bb4df4a6e6e60470",
            "79d5473b43924c7ea3713039c1eb7cf9",
            "17f0473d2d37415cbf6be75c7af752dc",
            "e603dadd4f66415e9c24edeaf148d456",
            "c44b9995109f42d784944f5029d41c6e",
            "ad032d4c642f46c2af198a437fcf4901",
            "e24921676d484c438a1394cc901122ee",
            "4ae7b404d2f04a11aff8546192b10b17",
            "996f8996b20541838aec6a12dcfa1573",
            "aed395de1fee4511b1ce9658ff81a3ac",
            "af2a61df681f4178a73b3ba581fcd7cb",
            "58882b9aef7d4201a8beec736d95d78c",
            "35a96613170b4b27892d4e11587cfadc",
            "aecc5fac105d48fe8e6584e6bcaa88d3",
            "63a52cdc676a4d698b6e28aed5fc9d6f",
            "3941b5d23f8446c7b2270fa94ff35972",
            "8dce37c572274cfba86ea43d764140f7",
            "a8237db6fd63485d9081e1a40e60388b",
            "e3d8c21d96374476ba014cffc7d12083",
            "5ccb723f0bfe4cec80b3a9a30c46bcd6",
            "866e321690cc4a1db87471fb59c8f7ce",
            "2791097a73f74adbad48430a68ba6537",
            "90846d764ff8491bbc1dd32728b83da3",
            "fed03caec5ae4f2eab913516dc75d5e8",
            "0a071d8b5cff4d459793b8cdd038f1b2",
            "dedb09ab77d14ed09a3ff5ca5d7a1a09",
            "6889df0f2f7545008c5a74856b5b81e2",
            "ce96f56cf5b149b9b705ad833a2e4103",
            "b4eacc04fb1749c8a88ea99a4abd207f",
            "32d9a503640b4ae8b31981515f511c20",
            "0a1ffcb91f8449d5b00637abf3fc8e5c",
            "a52517c186f44c72ab90837426998f99",
            "9427d2ec3a0f4df78ae53faf136a0590",
            "2e96cfced06b4f04a6e1068abfbd9224",
            "555a238bf9ca46038d7d01a46330807c",
            "5d17f4218dea4dcc9a48003bccafbad5",
            "78478664442d488485341a87f8bdd4f7",
            "44f9b6e1e6784f3397c0ae921d4b5af4",
            "d520fa104a314a38bd62800768197d2d",
            "4280afaa1675442abb9e8c56bdb76a7f",
            "835ff760a312493e9221d4064596ee73",
            "2e40696d889040419e8dec183bf025f2"
          ]
        },
        "id": "pfyc9RNM0jyF",
        "outputId": "85702dfc-08d5-47e4-9a93-6659c82b7fec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f97bd054fbfd4c0fad33ddc80b3d2488",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a42dd6abccc6401cbda13fd7f9c352f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1660868c5724a2a83391f1b69f5a494",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aed395de1fee4511b1ce9658ff81a3ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "866e321690cc4a1db87471fb59c8f7ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a52517c186f44c72ab90837426998f99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from haystack.nodes import Seq2SeqGenerator\n",
        "\n",
        "\n",
        "generator = Seq2SeqGenerator(model_name_or_path=\"vblagoje/bart_lfqa\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K0Ak37bH0om8"
      },
      "source": [
        "### Pipeline\n",
        "\n",
        "With a Haystack `Pipeline` we can stick together your building blocks to a search pipeline.\n",
        "Under the hood, `Pipelines` are Directed Acyclic Graphs (DAGs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSEm2wsS0zTF"
      },
      "outputs": [],
      "source": [
        "from haystack.pipelines import GenerativeQAPipeline\n",
        "\n",
        "pipe = GenerativeQAPipeline(generator, retriever)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mkbAK2TR01Ob"
      },
      "source": [
        "**Ask Questions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvzRis6-0-7i"
      },
      "outputs": [],
      "source": [
        "def askQuestion(question):\n",
        "  try:\n",
        "    query = pipe.run(\n",
        "        query=question, params={\"Retriever\": {\"top_k\": 3}}\n",
        "    )\n",
        "    answer = query['answers'][0].answer\n",
        "    score = query['documents'][0].score\n",
        "\n",
        "    result = {\n",
        "        'question': question,\n",
        "        'answer': answer,\n",
        "        'score': score\n",
        "    }\n",
        "\n",
        "    return result\n",
        "  except Exception:\n",
        "    raise Exception(\"face not detected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXSPrDfx06Ix",
        "outputId": "4ced9376-30bd-43be-812a-55fbce044e6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What is a one-to-one relationship?',\n",
              " 'answer': 'A one-to-one relationship is where each record in one table is associated with exactly one record in another table, and vice versa.',\n",
              " 'score': 0.6971657551119452}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question=  \"What is a one-to-one relationship?\"\n",
        "askQuestion(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ8LAYT5_0qO",
        "outputId": "54eb02e7-2e40-4c94-edf5-0d8f861e2091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/pytorch-flask-api\n"
          ]
        }
      ],
      "source": [
        "cd '/content/drive/MyDrive/pytorch-flask-api'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCfJ2EbH7Ctw",
        "outputId": "5568b97b-3e8f-40d7-a4b1-53f43cef3d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.3.0 pymongo-4.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pymongo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXQ2BehW7GO1"
      },
      "outputs": [],
      "source": [
        "from pymongo import MongoClient\n",
        "# Replace <connection_string> with your modified MongoDB Atlas connection string\n",
        "client = MongoClient(\"mongodb+srv://<user-name>:<password>@cluster0.fz59ulb.mongodb.net/studentDb?retryWrites=true&w=majority\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJGB5CA_7bxA"
      },
      "outputs": [],
      "source": [
        "# Replace <database_name> with the name of your database\n",
        "db = client.get_database(\"studentDb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0IvPx4-8DwU"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "import json\n",
        "\n",
        "def download_image(url, filename, download_path):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        filepath = os.path.join(download_path, filename)\n",
        "        with open(filepath, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        return filepath\n",
        "    return None\n",
        "\n",
        "def download_images_from_mongodb():\n",
        "    # Specify the download directory\n",
        "    download_path = \"/content/drive/MyDrive/pytorch-flask-api/persons\"\n",
        "\n",
        "    # Create the download directory if it doesn't exist\n",
        "    os.makedirs(download_path, exist_ok=True)\n",
        "\n",
        "    # Replace <collection_name> with the name of your collection\n",
        "    collection = db.get_collection(\"students\")\n",
        "\n",
        "    # Find documents where uploadOnServer is False\n",
        "    query = {\"uploadOnServer\": False}\n",
        "    cursor = collection.find(query)\n",
        "\n",
        "    # Iterate over the documents and download the images\n",
        "    for document in cursor:\n",
        "        name = document['name']\n",
        "        student_id = str(document['_id'])\n",
        "        image_url = document['image']\n",
        "\n",
        "        # Create a JSON string representation of the object\n",
        "        object_data = {\n",
        "            \"name\": name,\n",
        "            \"student_id\":student_id\n",
        "        }\n",
        "        json_str = json.dumps(object_data)\n",
        "\n",
        "        # Use the JSON string as the filename\n",
        "        filename = f\"{json_str}.jpeg\"\n",
        "\n",
        "        # Download the image\n",
        "        filepath = download_image(image_url, filename, download_path)\n",
        "\n",
        "        if filepath:\n",
        "            # Update the 'uploadOnServer' status to True\n",
        "            query = {\"_id\": document['_id']}\n",
        "            update = {\"$set\": {\"uploadOnServer\": True}}\n",
        "            collection.update_one(query, update)\n",
        "            print(f\"Image downloaded and status updated for document: {document['_id']}\")\n",
        "            print(f\"Image saved at: {filepath}\")\n",
        "        else:\n",
        "            print(f\"Image download failed for document: {document['_id']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgWD0q_bEIeY"
      },
      "outputs": [],
      "source": [
        "# Call the function to download images from MongoDB\n",
        "download_images_from_mongodb()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mft-AXQPakzf",
        "outputId": "db4d0975-36d6-40ed-fb50-6a1ddc7464c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mongoengine\n",
            "  Downloading mongoengine-0.27.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.6/110.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pymongo<5.0,>=3.4 in /usr/local/lib/python3.10/dist-packages (from mongoengine) (4.3.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0,>=3.4->mongoengine) (2.3.0)\n",
            "Installing collected packages: mongoengine\n",
            "Successfully installed mongoengine-0.27.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mongoengine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKnAvfHxaeix"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sKA0dChasel"
      },
      "outputs": [],
      "source": [
        "from bson.objectid import ObjectId\n",
        "attendance_collection = db['attendances']\n",
        "students_collection = db['students']\n",
        "class Attendance:\n",
        "    @staticmethod\n",
        "    def create_attendance(student_id):\n",
        "      try:\n",
        "        # Check if the student_id exists in the students collection\n",
        "        if not students_collection.count_documents({'_id': ObjectId(student_id)}):\n",
        "            raise ValueError('Invalid student_id')\n",
        "                # Get the current date and time\n",
        "        current_time = datetime.now()\n",
        "        attendance_doc = {\n",
        "            'attendance_time': current_time,\n",
        "            'student': student_id\n",
        "        }\n",
        "        attendance_collection.insert_one(attendance_doc)\n",
        "      except Exception:\n",
        "        raise Exception(\"face not detected\")        "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rRcn0zC739z5"
      },
      "source": [
        "## **Install ngrok**\n",
        "\n",
        "ngrok is cross-platform application that exposes local server ports to the Internet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiKRQ_hJ3jXg",
        "outputId": "2e3d4250-3b3d-4111-e4c7-9ec1b4e6f7c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.27.1)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.2)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw5PsSUg4C78",
        "outputId": "69cf50e1-5ea9-49ef-e3d0-a053dac175d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-23 05:10:43--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.237.133.81, 52.202.168.65, 18.205.222.128, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.237.133.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13856790 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.tgz.35’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.21M  11.8MB/s    in 1.1s    \n",
            "\n",
            "2023-05-23 05:10:45 (11.8 MB/s) - ‘ngrok-stable-linux-amd64.tgz.35’ saved [13856790/13856790]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTVt6HsQ37Eo",
        "outputId": "85f4bf5d-c72c-4e80-b4f2-0c9ddbae5d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deb https://ngrok-agent.s3.amazonaws.com buster main\n",
            "Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:3 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Get:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:9 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Get:12 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,270 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,721 kB]\n",
            "Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n",
            "Get:15 https://ngrok-agent.s3.amazonaws.com buster InRelease [20.3 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,197 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,344 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,408 kB]\n",
            "Get:19 https://ngrok-agent.s3.amazonaws.com buster/main amd64 Packages [2,252 B]\n",
            "Fetched 12.3 MB in 2s (7,881 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "25 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  ngrok\n",
            "0 upgraded, 1 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 6,420 kB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 https://ngrok-agent.s3.amazonaws.com buster/main amd64 ngrok amd64 3.3.0 [6,420 kB]\n",
            "Fetched 6,420 kB in 2s (3,127 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package ngrok.\n",
            "(Reading database ... 122531 files and directories currently installed.)\n",
            "Preparing to unpack .../archives/ngrok_3.3.0_amd64.deb ...\n",
            "Unpacking ngrok (3.3.0) ...\n",
            "Setting up ngrok (3.3.0) ...\n"
          ]
        }
      ],
      "source": [
        "!curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null && echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | sudo tee /etc/apt/sources.list.d/ngrok.list && sudo apt update && sudo apt install ngrok"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeFHGl345KcV"
      },
      "source": [
        "Sign up link - https://dashboard.ngrok.com/signup?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptqts0XP2-cF",
        "outputId": "5f8cea20-a8f0-40df-febc-dc441dd285ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken <get-your-token>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to7A84_3bjCC",
        "outputId": "865b8ae0-58db-45ea-a897-e90da10643be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.3)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=79bbd2aec877ef939a8a3033157dcad5579ef9d567e5aab5c6782f6daf3ae726\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-dScc47cj-Q"
      },
      "outputs": [],
      "source": [
        "import face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnK3re3HGEo-",
        "outputId": "9141be53-31dc-408d-fbec-f93dc53a95f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepface\n",
            "  Downloading deepface-0.0.79-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.65.0)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.6.6)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (8.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.7.0.72)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.12.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.12.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.4)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.13-py3-none-any.whl (16 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.3.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.11.2)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2022.7.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.8)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (23.1)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow>=1.9.0->deepface)\n",
            "  Downloading protobuf-4.23.1-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=1.9.0->deepface) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=1.9.0->deepface) (1.10.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (2.1.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (1.8.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (3.2.2)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=2e842b4dc09f80a275c31240e6ae956506ea8db7159b13f074b9e4f897c895af\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: protobuf, gunicorn, fire, mtcnn, retina-face, deepface\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.2\n",
            "    Uninstalling protobuf-3.20.2:\n",
            "      Successfully uninstalled protobuf-3.20.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "farm-haystack 1.18.0rc0 requires protobuf<=3.20.2, but you have protobuf 4.23.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deepface-0.0.79 fire-0.5.0 gunicorn-20.1.0 mtcnn-0.1.1 protobuf-4.23.1 retina-face-0.0.13\n"
          ]
        }
      ],
      "source": [
        "!pip install deepface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAV-C-pQjkvt",
        "outputId": "50c0b496-f4b1-4164-bcce-a92a3e96f7f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.22.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.27.1)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.4)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.1\n",
            "    Uninstalling graphviz-0.20.1:\n",
            "      Successfully uninstalled graphviz-0.20.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mxnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZvBf1XQnpAH",
        "outputId": "c8dc7a75-4bec-4c93-8673-c67cf1dd0deb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model', '0000']\n",
            "loading model 0\n",
            "['genderage_v1/model', '0000']\n",
            "loading genderage_v1/model 0\n"
          ]
        }
      ],
      "source": [
        "import face_model\n",
        "import argparse\n",
        "import cv2\n",
        "from time import sleep\n",
        "import os\n",
        "import unicodedata\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def eu_dist(x, y):\n",
        "    d = 0.0\n",
        "    for i in range(len(x)):\n",
        "        d += pow((float(x[i]) - float(y[i])), 2)\n",
        "    d = math.sqrt(d)\n",
        "    return d/len(x)\n",
        "\n",
        "\n",
        "def save_encodings(imgs, name, model):\n",
        "    global known_encodings, known_names\n",
        "    for i in range(0, len(imgs)):\n",
        "        im = cv2.imread(imgs[i])\n",
        "        img, bbox = model.get_input(im, th=0.98)\n",
        "        if img is not None:\n",
        "            f2 = model.get_feature(img[0])\n",
        "            known_encodings.append(f2)\n",
        "            known_names.append(name[i])\n",
        "        else:\n",
        "            print('Warning: No face Detected for '+name[i]+'\\n')\n",
        "\n",
        "\n",
        "def str_to_ndarray(input):\n",
        "    temp = input.split(',')\n",
        "    temp = temp[0:len(temp)-1]\n",
        "    for t in range(0, len(temp)):\n",
        "        temp[t] = float(unicodedata.normalize(\n",
        "            'NFKD', temp[t]).encode('ascii', 'ignore'))\n",
        "    temp = np.asarray(temp)\n",
        "    return temp\n",
        "\n",
        "\n",
        "known_encodings = []\n",
        "known_names = []\n",
        "\n",
        "\n",
        "def get_encodings():\n",
        "    global known_names\n",
        "    global known_encodings\n",
        "    known_encodings = []\n",
        "    known_names = []\n",
        "    qry = 'select name,encodings from encodings;'\n",
        "    cnx = open_connection()\n",
        "    if cnx:\n",
        "        print('Getting encoding from Database')\n",
        "        cursor = cnx.cursor()\n",
        "        cursor.execute(qry)\n",
        "        data = cursor.fetchall()\n",
        "        for dat in data:\n",
        "            name = dat[0]\n",
        "            encodings = dat[1]\n",
        "            known_encodings.append(str_to_ndarray(encodings))\n",
        "            known_names.append(unicodedata.normalize(\n",
        "                'NFKD', name).encode('ascii', 'ignore'))\n",
        "        cursor.reset()\n",
        "        close_connection(cnx)\n",
        "        known_encodings = np.asarray(known_encodings)\n",
        "        try:\n",
        "            os.remove(\"encodings.npy\")\n",
        "            os.remove(\"names.npy\")\n",
        "            np.save('encodings.npy', known_encodings)\n",
        "            np.save('names.npy', known_names)\n",
        "            print('Latest Encodings are saved')\n",
        "        except:\n",
        "            print('Unable to store new encodings')\n",
        "        return known_names, known_encodings\n",
        "    else:\n",
        "        print('Getting encodings from file')\n",
        "        get_encodings_from_file()\n",
        "\n",
        "\n",
        "def get_encodings_from_file():\n",
        "    global known_names\n",
        "    global known_encodings\n",
        "    if os.path.exists('./encodings.npy') and os.path.exists('./names.npy'):\n",
        "        known_encodings = np.load('encodings.npy')\n",
        "        known_names = np.load('names.npy')\n",
        "    return known_names, known_encodings\n",
        "\n",
        "\n",
        "def face_recog(test_vec, th):\n",
        "    dis = eu_dist(known_encodings[0], test_vec)\n",
        "    min_dis = dis\n",
        "    name = known_names[0]\n",
        "    for vec in range(1, len(known_encodings)):\n",
        "        dis = eu_dist(known_encodings[vec], test_vec)\n",
        "        # print(known_names[vec])\n",
        "        # print(dis)\n",
        "        if dis < min_dis:\n",
        "            min_dis = dis\n",
        "            name = known_names[vec]\n",
        "    if min_dis < th:\n",
        "        return name\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "\n",
        "def FaceMain(image):\n",
        "    try:\n",
        "      result = dict()\n",
        "      global args, model\n",
        "\n",
        "      img, bbox = model.get_input(image, th=0.98)\n",
        "      if img is not None:\n",
        "          for im in range(0, len(img)):\n",
        "              f2 = model.get_feature(img[im])\n",
        "              fhab = model.get_ga(img[im])\n",
        "              name = face_recog(f2, 0.0021)\n",
        "              gender, age = fhab\n",
        "              result = {\"name\": name, \"gender\": gender, \"age\": age}\n",
        "              return result\n",
        "    except Exception:\n",
        "      raise Exception(\"face not detected\")\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='face model test')\n",
        "# # general\n",
        "parser.add_argument('--image-size', default='112,112', help='')\n",
        "parser.add_argument('--model', default='model-0000',\n",
        "                    help='path to load model.')\n",
        "parser.add_argument(\n",
        "    '--ga-model', default='genderage_v1/model-0000', help='path to load model.')\n",
        "parser.add_argument('--gpu', default=0, type=int, help='gpu id')\n",
        "parser.add_argument('--det', default=0, type=int,\n",
        "                    help='mtcnn option, 1 means using R+O, 0 means detect from begining')\n",
        "parser.add_argument('--flip', default=0, type=int,\n",
        "                    help='whether do lr flip aug')\n",
        "parser.add_argument('--threshold', default=1.24,\n",
        "                    type=float, help='ver dist threshold')\n",
        "parser.add_argument(\"-f\", \"--file\", required=False)\n",
        "args = parser.parse_args()\n",
        "model = face_model.FaceModel(args)\n",
        "base_path = r'persons'\n",
        "images_path = []\n",
        "names_list = []\n",
        "for im in os.listdir(base_path):\n",
        "    images_path.append(os.path.join(base_path, im))\n",
        "    names_list.append(im.split('.')[0])\n",
        "\n",
        "if 'persons/.ipynb_checkpoints' in images_path:\n",
        "    images_path.remove('persons/.ipynb_checkpoints')\n",
        "if '' in names_list:\n",
        "  names_list.remove('')\n",
        "save_encodings(images_path, names_list, model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDIny-JN1Epd"
      },
      "outputs": [],
      "source": [
        "def download_and_append_encodings():\n",
        "    download_images_from_mongodb()\n",
        "    images_path = []\n",
        "    names_list = []\n",
        "    for im in os.listdir(base_path):\n",
        "        images_path.append(os.path.join(base_path, im))\n",
        "        names_list.append(im.split('.')[0])\n",
        "\n",
        "    if 'persons/.ipynb_checkpoints' in images_path:\n",
        "        images_path.remove('persons/.ipynb_checkpoints')\n",
        "    if '' in names_list:\n",
        "      names_list.remove('')\n",
        "    save_encodings(images_path, names_list, model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLkYIIL5YvA1"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "from keras import backend as K\n",
        "import imutils\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import keras\n",
        "import requests\n",
        "from scipy.spatial import distance as dist\n",
        "from imutils import face_utils\n",
        "import time\n",
        "import dlib\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "import collections\n",
        "import random\n",
        "import face_recognition\n",
        "import pickle\n",
        "import math\n",
        "import threading\n",
        "import tensorflow as tf\n",
        "\n",
        "num_cores = 4\n",
        "num_CPU = 1\n",
        "num_GPU = 1\n",
        "\n",
        "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=num_cores,\n",
        "                                  inter_op_parallelism_threads=num_cores,\n",
        "                                  allow_soft_placement=True,\n",
        "                                  device_count={'CPU': num_CPU,\n",
        "                                                'GPU': num_GPU}\n",
        "                                  )\n",
        "\n",
        "session = tf.compat.v1.Session(config=config)\n",
        "K.set_session(session)\n",
        "\n",
        "\n",
        "class FacialLandMarksPosition:\n",
        "    \"\"\"\n",
        "    The indices points to the various facial features like left ear, right ear, nose, etc.,\n",
        "    that are mapped from the Facial Landmarks used by dlib's FacialLandmarks predictor.\n",
        "    \"\"\"\n",
        "    left_eye_start_index, left_eye_end_index = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
        "    right_eye_start_index, right_eye_end_index = face_utils.FACIAL_LANDMARKS_IDXS[\n",
        "        \"right_eye\"]\n",
        "\n",
        "\n",
        "facial_landmarks_predictor = 'models/68_face_landmarks_predictor.dat'\n",
        "predictor = dlib.shape_predictor(facial_landmarks_predictor)\n",
        "\n",
        "modelForEye = load_model('models/weights.149-0.01.hdf5')\n",
        "\n",
        "\n",
        "def predict_eye_state(model, image):\n",
        "    image = cv2.resize(image, (20, 10))\n",
        "    image = image.astype(dtype=np.float32)\n",
        "\n",
        "    image_batch = np.reshape(image, (1, 10, 20, 1))\n",
        "    image_batch = tf.keras.applications.mobilenet.preprocess_input(image_batch)\n",
        "\n",
        "    return np.argmax(modelForEye.predict(image_batch)[0])\n",
        "\n",
        "#cap = cv2.VideoCapture(0)\n",
        "\n",
        "\n",
        "def eyeMain():\n",
        "    try:\n",
        "      left = None\n",
        "      right = None\n",
        "      scale = 0.5\n",
        "      while(True):\n",
        "          #c = time.time()\n",
        "\n",
        "          # Capture frame-by-frame\n",
        "          #ret, frame = cap.read()\n",
        "          frame = cv2.imread('your_file_name.jpg')\n",
        "          image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "          original_height, original_width = image.shape[:2]\n",
        "\n",
        "          resized_image = cv2.resize(image,  (0, 0), fx=scale, fy=scale)\n",
        "          lab = cv2.cvtColor(resized_image, cv2.COLOR_BGR2LAB)\n",
        "\n",
        "          l, _, _ = cv2.split(lab)\n",
        "\n",
        "          resized_height, resized_width = l.shape[:2]\n",
        "          height_ratio, width_ratio = original_height / \\\n",
        "              resized_height, original_width / resized_width\n",
        "\n",
        "          face_locations = face_recognition.face_locations(l, model='hog')\n",
        "\n",
        "          if len(face_locations):\n",
        "              top, right, bottom, left = face_locations[0]\n",
        "              x1, y1, x2, y2 = left, top, right, bottom\n",
        "\n",
        "              x1 = int(x1 * width_ratio)\n",
        "              y1 = int(y1 * height_ratio)\n",
        "              x2 = int(x2 * width_ratio)\n",
        "              y2 = int(y2 * height_ratio)\n",
        "\n",
        "          # draw face rectangle\n",
        "\n",
        "              gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "              shape = predictor(gray, dlib.rectangle(x1, y1, x2, y2))\n",
        "\n",
        "              face_landmarks = face_utils.shape_to_np(shape)\n",
        "\n",
        "              left_eye_indices = face_landmarks[FacialLandMarksPosition.left_eye_start_index:\n",
        "                                                FacialLandMarksPosition.left_eye_end_index]\n",
        "\n",
        "              (x, y, w, h) = cv2.boundingRect(np.array([left_eye_indices]))\n",
        "              left_eye = gray[y:y + h, x:x + w]\n",
        "\n",
        "              right_eye_indices = face_landmarks[FacialLandMarksPosition.right_eye_start_index:\n",
        "                                                FacialLandMarksPosition.right_eye_end_index]\n",
        "\n",
        "              (x, y, w, h) = cv2.boundingRect(np.array([right_eye_indices]))\n",
        "              right_eye = gray[y:y + h, x:x + w]\n",
        "\n",
        "              left_eye_open = 'yes' if predict_eye_state(\n",
        "                  model=modelForEye, image=left_eye) else 'no'\n",
        "              right_eye_open = 'yes' if predict_eye_state(\n",
        "                  model=modelForEye, image=right_eye) else 'no'\n",
        "\n",
        "              left = '{}'.format(left_eye_open)\n",
        "              right = '{}'.format(right_eye_open)\n",
        "          # print(right)\n",
        "          #print('left eye open: {0}    right eye open: {1}'.format(left_eye_open, right_eye_open))\n",
        "              break\n",
        "              if left_eye_open == 'yes' and right_eye_open == 'yes':\n",
        "                  cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "              else:\n",
        "                  cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "          #cv2.imshow('right_eye', right_eye)\n",
        "        # cv2.imshow('left_eye', left_eye)\n",
        "\n",
        "          break\n",
        "\n",
        "  # When everything done, release the capture\n",
        "  # cap.release()\n",
        "      cv2.destroyAllWindows()\n",
        "      # print(left)\n",
        "      # print(right)\n",
        "      if(left == None or right == None):\n",
        "          return None\n",
        "      return{'left': left, 'right': right}\n",
        "    except Exception:\n",
        "      raise Exception(\"eyes not detected\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_iPubVac3Ku"
      },
      "outputs": [],
      "source": [
        "# image_file = cv2.imread(r'your_file_name.jpg')\n",
        "# result = FaceMain(image_file)\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_4O0PD3cj72"
      },
      "outputs": [],
      "source": [
        "# eyeMain()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VjLEYASZXMT"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def get_current_date():  \n",
        "    \"\"\"\n",
        "    Get the current date in the format: DayName, DayWithOrdinalSuffix Month Year\n",
        "    Example: 20th of May 2023\n",
        "    \"\"\"\n",
        "    current_date = datetime.now()\n",
        "    day = current_date.day\n",
        "    ordinal_suffix = \"th\" if 11 <= day <= 13 else {1: \"st\", 2: \"nd\", 3: \"rd\"}.get(day % 10, \"th\")\n",
        "    formatted_date = current_date.strftime(f\"%d{ordinal_suffix} of %B %Y\")\n",
        "    return formatted_date\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z613__4LZjUE"
      },
      "outputs": [],
      "source": [
        "import pytz\n",
        "\n",
        "def get_current_time():\n",
        "    \"\"\"\n",
        "    Get the current time in Lahore with AM/PM.\n",
        "    Example: \"ten thirty AM\" or \"ten thirty PM\"\n",
        "    \"\"\"\n",
        "    timezone = pytz.timezone('Asia/Karachi')\n",
        "    current_time = datetime.now(timezone).time()\n",
        "    hour = current_time.hour\n",
        "    minute = current_time.minute\n",
        "    \n",
        "    # Convert hour to words\n",
        "    if hour == 0:\n",
        "        hour_word = \"twelve\"\n",
        "    elif hour <= 12:\n",
        "        hour_word = num_to_word(hour)\n",
        "    else:\n",
        "        hour_word = num_to_word(hour - 12)\n",
        "    \n",
        "    # Convert minute to words\n",
        "    if minute == 0:\n",
        "        minute_word = \"o'clock\"\n",
        "    else:\n",
        "        minute_word = num_to_word(minute)\n",
        "    \n",
        "    # Determine AM/PM\n",
        "    am_pm = \"AM\" if hour < 12 else \"PM\"\n",
        "    \n",
        "    # Construct the time description\n",
        "    time_description = f\"{hour_word} {minute_word} {am_pm}\"\n",
        "    \n",
        "    return time_description\n",
        "\n",
        "def num_to_word(num):\n",
        "    \"\"\"\n",
        "    Convert a number to its word representation.\n",
        "    \"\"\"\n",
        "    units = [\n",
        "        \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\",\n",
        "        \"six\", \"seven\", \"eight\", \"nine\", \"ten\", \"eleven\",\n",
        "        \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\",\n",
        "        \"seventeen\", \"eighteen\", \"nineteen\"\n",
        "    ]\n",
        "    tens = [\n",
        "        \"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\",\n",
        "        \"sixty\", \"seventy\", \"eighty\", \"ninety\"\n",
        "    ]\n",
        "    \n",
        "    if num < 20:\n",
        "        return units[num]\n",
        "    else:\n",
        "        tens_digit = num // 10\n",
        "        ones_digit = num % 10\n",
        "        return f\"{tens[tens_digit]} {units[ones_digit]}\"\n",
        "\n",
        "# Get the current time in Lahore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi-_mWg-ZthZ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import math\n",
        "\n",
        "def kelvin_to_celsius(kelvin):\n",
        "    return kelvin - 273.15\n",
        "\n",
        "def get_weather(city_name, api_key):\n",
        "    base_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
        "    complete_url = base_url + \"appid=\" + api_key + \"&q=\" + city_name\n",
        "    response = requests.get(complete_url)\n",
        "    data = response.json()\n",
        "    \n",
        "    if data[\"cod\"] != \"404\":\n",
        "        main_info = data[\"main\"]\n",
        "        current_temperature = main_info[\"temp\"]\n",
        "        feels_like = main_info[\"feels_like\"]\n",
        "        current_pressure = main_info[\"pressure\"]\n",
        "        current_humidity = main_info[\"humidity\"]\n",
        "        weather_description = data[\"weather\"][0][\"description\"]\n",
        "        \n",
        "        result = f\"{weather_description} is currently in {city_name}. The current temperature in {city_name} is {math.floor(kelvin_to_celsius(current_temperature))} degrees Celsius, feels like {math.floor(kelvin_to_celsius(feels_like))} degrees Celsius. The atmospheric pressure is {current_pressure} hPa. The humidity level is {current_humidity}%.\"\n",
        "        return result\n",
        "    else:\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjXNd_hFdG2k",
        "outputId": "76ca0b27-8c05-47d5-e25b-fe1dbc40cd4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n",
            "facial_expression_model_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5\n",
            "To: /root/.deepface/weights/facial_expression_model_weights.h5\n",
            "100%|██████████| 5.98M/5.98M [00:00<00:00, 30.4MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "race_model_single_batch.h5 will be downloaded...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/race_model_single_batch.h5\n",
            "To: /root/.deepface/weights/race_model_single_batch.h5\n",
            "100%|██████████| 537M/537M [00:08<00:00, 61.5MB/s]\n",
            "Action: race:   0%|          | 0/2 [00:00<?, ?it/s]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc3bf4a7c70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Optional dependency 'langdetect' was used but it isn't installed.\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Action: emotion:  50%|█████     | 1/2 [00:05<00:05,  6.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc3be2a8310> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Optional dependency 'langdetect' was used but it isn't installed.\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Action: emotion: 100%|██████████| 2/2 [00:06<00:00,  3.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "angry\n",
            "white\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from deepface import DeepFace\n",
        "obj = DeepFace.analyze(img_path=\"your_file_name.jpg\",\n",
        "                       actions=[ 'race', 'emotion'])\n",
        "print(obj[0]['dominant_emotion'])\n",
        "print(obj[0]['dominant_race'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXDs0ZJItdRx"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def putlabels(x):\n",
        "\n",
        "    if str(x) == '0':\n",
        "        return 'neutral'\n",
        "    elif str(x) == '1':\n",
        "        return 'happy'\n",
        "    elif str(x) == '2':\n",
        "        return 'sad'\n",
        "    elif str(x) == '3':\n",
        "        return 'surprise'\n",
        "    else:\n",
        "        return 'anger'\n",
        "\n",
        "\n",
        "def net_face(frame, shape):\n",
        "\n",
        "    net = cv2.dnn.readNet(face_model + '.xml', face_model + '.bin')\n",
        "    blob = cv2.dnn.blobFromImage(frame, size=shape, ddepth=cv2.CV_8U)\n",
        "    net.setInput(blob)\n",
        "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
        "\n",
        "    out = net.forward()\n",
        "    return out\n",
        "\n",
        "\n",
        "def net_emote(frame, shape):\n",
        "\n",
        "    net = cv2.dnn.readNet(emote_model + '.xml', emote_model + '.bin')\n",
        "    blob = cv2.dnn.blobFromImage(frame, size=shape, ddepth=cv2.CV_8U)\n",
        "    net.setInput(blob)\n",
        "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
        "\n",
        "    out = net.forward()\n",
        "    return out\n",
        "\n",
        "\n",
        "face_model = 'face-detection-retail-0005'\n",
        "emote_model = 'emotions-recognition-retail-0003'\n",
        "path = 'in.mp4'\n",
        "\n",
        "#cap = cv2.VideoCapture(0)\n",
        "\n",
        "\n",
        "def mainForEmotion():\n",
        "    frame = cv2.imread(\"your_file_name.jpg\")\n",
        "#frame_width = int(cap.get(3))\n",
        "#frame_height = int(cap.get(4))\n",
        "\n",
        "\n",
        "#writer = cv2.VideoWriter('out.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 25, (frame_width,frame_height))\n",
        "    returnvalue = None\n",
        "    while(True):\n",
        "        #ret, frame = cap.read()\n",
        "\n",
        "        # if ret == False:\n",
        "        #print('End of video')\n",
        "        # break\n",
        "\n",
        "        out = net_face(frame, (300, 300))\n",
        "\n",
        "        for detection in out.reshape(-1, 7):\n",
        "\n",
        "            conf = float(detection[2])\n",
        "            xmin = int(detection[3] * frame.shape[1])\n",
        "            ymin = int(detection[4] * frame.shape[0])\n",
        "            xmax = int(detection[5] * frame.shape[1])\n",
        "            ymax = int(detection[6] * frame.shape[0])\n",
        "\n",
        "            if conf > 0.65:\n",
        "\n",
        "                soft = net_emote(frame, (64, 64))\n",
        "                emo_pred = np.reshape(soft, (5,))\n",
        "                emo_pred = list(emo_pred)\n",
        "                returnvalue = putlabels(emo_pred.index(max(emo_pred)))\n",
        "            #cv2.rectangle(frame, (xmin,ymin),(xmax,ymax), (0,128,255), 2)\n",
        "            #cv2.putText(frame, putlabels(emo_pred.index(max(emo_pred))) , (xmin, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "\n",
        "        # cv2.imshow('Emotion-Recognition',frame)\n",
        "        break\n",
        "    # writer.write(frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    return returnvalue\n",
        "    # print(returnvalue)\n",
        "\n",
        "# cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# frame=cv2.imread(\"your_file_name.jpg\")\n",
        "# #frame_width = int(cap.get(3))\n",
        "# #frame_height = int(cap.get(4))\n",
        "\n",
        "# #writer = cv2.VideoWriter('out.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 25, (frame_width,frame_height))\n",
        "# returnvalue=None\n",
        "# while(True):\n",
        "#     #ret, frame = cap.read()\n",
        "\n",
        "#     #if ret == False:\n",
        "#         #print('End of video')\n",
        "#        # break\n",
        "\n",
        "#     out = net_face(frame, (300,300))\n",
        "\n",
        "#     for detection in out.reshape(-1,7):\n",
        "\n",
        "#         conf = float(detection[2])\n",
        "#         xmin = int(detection[3] * frame.shape[1])\n",
        "#         ymin = int(detection[4] * frame.shape[0])\n",
        "#         xmax = int(detection[5] * frame.shape[1])\n",
        "#         ymax = int(detection[6] * frame.shape[0])\n",
        "\n",
        "#         if conf > 0.65:\n",
        "\n",
        "#             soft = net_emote(frame,(64,64))\n",
        "#             emo_pred = np.reshape(soft, (5,))\n",
        "#             emo_pred = list(emo_pred)\n",
        "#             returnvalue=putlabels(emo_pred.index(max(emo_pred)))\n",
        "#             #cv2.rectangle(frame, (xmin,ymin),(xmax,ymax), (0,128,255), 2)\n",
        "#             #cv2.putText(frame, putlabels(emo_pred.index(max(emo_pred))) , (xmin, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "\n",
        "#         #cv2.imshow('Emotion-Recognition',frame)\n",
        "#     break\n",
        "#     #writer.write(frame)\n",
        "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "#         break\n",
        "# print(returnvalue)\n",
        "# #cap.release()\n",
        "# cv2.destroyAllWindows()\n",
        "# #writer.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuECLWWXxbGh",
        "outputId": "c4dfdd5c-d5a4-45ce-f009-483a90f6316d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python-inference-engine\n",
            "  Downloading opencv_python_inference_engine-2022.1.5-py3-none-manylinux1_x86_64.whl (41.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from opencv-python-inference-engine) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install opencv-python-inference-engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BjWAQkcsVW4"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import random\n",
        "import nltk\n",
        "import numpy as num\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHjsFvLasar7"
      },
      "outputs": [],
      "source": [
        "# Load the saved model\n",
        "ourNewModel = load_model('/content/drive/MyDrive/gfgModelFinal.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlOf04MrsfZS"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "# File path of the JSON file\n",
        "file_path = '/content/drive/MyDrive/intents.json'\n",
        "with open(file_path) as file:\n",
        "    ourData = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c67m7VDhsnG2"
      },
      "outputs": [],
      "source": [
        "lm = WordNetLemmatizer() #for getting words\n",
        "# lists\n",
        "ourClasses = []\n",
        "newWords = []\n",
        "documentX = []\n",
        "documentY = []\n",
        "# Each intent is tokenized into words and the patterns and their associated tags are added to their respective lists.\n",
        "for intent in ourData[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        ournewTkns = nltk.word_tokenize(pattern)# tokenize the patterns\n",
        "        newWords.extend(ournewTkns)# extends the tokens\n",
        "        documentX.append(pattern)\n",
        "        documentY.append(intent[\"tag\"])\n",
        "\n",
        "\n",
        "    if intent[\"tag\"] not in ourClasses:# add unexisting tags to their respective classes\n",
        "        ourClasses.append(intent[\"tag\"])\n",
        "\n",
        "newWords = [lm.lemmatize(word.lower()) for word in newWords if word not in string.punctuation] # set words to lowercase if not in punctuation\n",
        "newWords = sorted(set(newWords))# sorting words\n",
        "ourClasses = sorted(set(ourClasses))# sorting classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ztczc24ysqe_"
      },
      "outputs": [],
      "source": [
        "def ourText(text):\n",
        "  newtkns = nltk.word_tokenize(text)\n",
        "  newtkns = [lm.lemmatize(word) for word in newtkns]\n",
        "  return newtkns\n",
        "\n",
        "def wordBag(text, vocab):\n",
        "  newtkns = ourText(text)\n",
        "  bagOwords = [0] * len(vocab)\n",
        "  for w in newtkns:\n",
        "    for idx, word in enumerate(vocab):\n",
        "      if word == w:\n",
        "        bagOwords[idx] = 1\n",
        "  return num.array(bagOwords)\n",
        "\n",
        "def Pclass(text, vocab, labels):\n",
        "  bagOwords = wordBag(text, vocab)\n",
        "  # print(num.array([bagOwords]))\n",
        "  ourResult = ourNewModel.predict(num.array([bagOwords]))[0]\n",
        "  print(ourResult)\n",
        "  newThresh = 0.9\n",
        "  yp = [[idx, res] for idx, res in enumerate(ourResult) if res > newThresh]\n",
        "\n",
        "  yp.sort(key=lambda x: x[1], reverse=True)\n",
        "  newList = []\n",
        "  for r in yp:\n",
        "    newList.append(labels[r[0]])\n",
        "  return newList\n",
        "\n",
        "def getRes(firstlist, fJson):\n",
        "  tag = firstlist[0]\n",
        "  listOfIntents = fJson[\"intents\"]\n",
        "  for i in listOfIntents:\n",
        "    if i[\"tag\"] == tag:\n",
        "      ourResult = random.choice(i[\"responses\"])\n",
        "      break\n",
        "  return ourResult"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmPVRK1i_q-H"
      },
      "outputs": [],
      "source": [
        "def convert_to_lowercase(string):\n",
        "    lowercase_string = string.lower()\n",
        "    return lowercase_string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynxFR05dsssw"
      },
      "outputs": [],
      "source": [
        "def askBot(newMessage):\n",
        "  # Example usage\n",
        "    newMessage = convert_to_lowercase(newMessage)\n",
        "    intents = Pclass(newMessage, newWords, ourClasses)\n",
        "    if intents:\n",
        "      ourResult = getRes(intents, ourData)\n",
        "      if ourResult==\"\":\n",
        "        return False\n",
        "      else:\n",
        "        return ourResult\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIuDWsy0fmxl"
      },
      "outputs": [],
      "source": [
        "from deepface import DeepFace\n",
        "\n",
        "\n",
        "def getRace():\n",
        "    try:\n",
        "        obj = DeepFace.analyze(img_path=\"your_file_name.jpg\", actions=['race'])\n",
        "        return obj[0][\"dominant_race\"]\n",
        "\n",
        "    except Exception:\n",
        "        raise Exception(\"face not detected\")\n",
        "def getEmotion():\n",
        "    try:\n",
        "      obj = DeepFace.analyze(img_path=\"your_file_name.jpg\",\n",
        "                              actions=['emotion'])\n",
        "      return obj[0][\"dominant_emotion\"]\n",
        "    except Exception:\n",
        "        raise Exception(\"face not detected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2PalbEhYjFaX",
        "outputId": "68ecc1da-e53f-413c-8fbf-4c35cae3155e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from flask-cors) (2.2.4)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.10/dist-packages (from flask-cors) (1.16.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (2.3.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.9->flask-cors) (2.1.2)\n",
            "Installing collected packages: flask-cors\n",
            "Successfully installed flask-cors-3.0.10\n"
          ]
        }
      ],
      "source": [
        "!pip install -U flask-cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K-BHguj938lk"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import json\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from threading import Thread\n",
        "from flask import Flask, jsonify, request,make_response\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask_cors import CORS\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "# run_with_ngrok(app)\n",
        "@app.route('/race', methods=['POST'])\n",
        "def predict():\n",
        "    if request.method == 'POST':\n",
        "      try:\n",
        "        file = request.files['file']\n",
        "        file.save(\"your_file_name.jpg\")\n",
        "        result=getRace()\n",
        "        return jsonify({'Race': result})      \n",
        "      except Exception as e:\n",
        "        response = make_response(jsonify({'message': str(e)}), 400)\n",
        "        return response\n",
        "\n",
        "@app.route('/emotion', methods=['POST'])\n",
        "def predictEmotion():\n",
        "    if request.method == 'POST':\n",
        "      try:\n",
        "        file = request.files['file']\n",
        "        file.save(\"your_file_name.jpg\")\n",
        "        result=getEmotion()\n",
        "        return jsonify({'emotion': result})\n",
        "      except Exception as e:\n",
        "        response = make_response(jsonify({'message': str(e)}), 400)\n",
        "        return response\n",
        "\n",
        "@app.route('/faceGenderAge', methods=['POST'])\n",
        "def predictFaceAgeGender():\n",
        "    if request.method == 'POST':\n",
        "      try:\n",
        "        file = request.files['file']\n",
        "        file.save(\"your_file_name.jpg\")\n",
        "        image_file = cv2.imread(r'your_file_name.jpg')\n",
        "        download_and_append_encodings()\n",
        "        result=FaceMain(image_file)\n",
        "        if(not result):\n",
        "            response = make_response(jsonify({'message': \"Could not detect face\"}), 400)\n",
        "            return response\n",
        "        object_data = json.loads(str(result['name']))\n",
        "        # Access the values in the dictionary\n",
        "        name = object_data['name']\n",
        "\n",
        "        return jsonify({'result':{'name': name,\n",
        "                        'age': str(result['age']),\n",
        "                        'gender': str(result['gender'])}})\n",
        "      except Exception as e:\n",
        "        response = make_response(jsonify({'message': str(e)}), 400)\n",
        "        return response\n",
        "\n",
        "@app.route('/eye', methods=['POST'])\n",
        "def predictEye():\n",
        "    if request.method == 'POST':\n",
        "      try:\n",
        "        file = request.files['file']\n",
        "        result=eyeMain()\n",
        "        if(not result):\n",
        "            response = make_response(jsonify({'message': \"Could not detect eyes\"}), 400)\n",
        "            return response\n",
        "        return {'result':result}\n",
        "      except Exception as e:\n",
        "        response = make_response(jsonify({'message': str(e)}), 400)\n",
        "        return response\n",
        "          \n",
        "@app.route('/date', methods=['POST'])\n",
        "def getDate():\n",
        "  if request.method == 'POST':\n",
        "    try:\n",
        "      result=get_current_date()\n",
        "      return jsonify({'date': result})\n",
        "    except:\n",
        "      response = make_response(jsonify({'message': \"could not get date something bad happend\"}), 400)\n",
        "      return response\n",
        "\n",
        "@app.route('/time', methods=['POST'])\n",
        "def getTime():\n",
        "  if request.method == 'POST':\n",
        "    try:\n",
        "      result=  get_current_time()\n",
        "      return jsonify({'time': result})\n",
        "    except:\n",
        "      response = make_response(jsonify({'message': \"could not get date something bad happend\"}), 400)\n",
        "      return response\n",
        "\n",
        "@app.route('/weather', methods=['POST'])\n",
        "def getWeather():\n",
        "  if request.method == 'POST':\n",
        "    try:\n",
        "      api_key = \"put-your-own-open-weather-api-key\"\n",
        "      city_name = \"Lahore\"\n",
        "      weather_info = get_weather(city_name, api_key)\n",
        "      return jsonify({\"weather\": weather_info})\n",
        "    except:\n",
        "      response = make_response(jsonify({'message': \"could not get date something bad happend\"}), 400)\n",
        "      return response\n",
        "\n",
        "@app.route('/qa', methods=['POST'])\n",
        "def getQA():\n",
        "  if request.method == 'POST':\n",
        "    try:\n",
        "      question = request.form['name']\n",
        "      result=askQuestion(question)\n",
        "      # Destructure the dictionary\n",
        "      question, answer, score = result['question'], result['answer'], result['score']\n",
        "      return jsonify({'answer': answer,'score':score})\n",
        "    except Exception as e:\n",
        "      response = make_response(jsonify({'message': str(e)}), 400)\n",
        "      return response\n",
        "\n",
        "@app.route('/studentAttendance', methods=['POST'])\n",
        "def storeAttendance():\n",
        "    if request.method == 'POST':\n",
        "      try:\n",
        "        file = request.files['file']\n",
        "        file.save(\"your_file_name.jpg\")\n",
        "        image_file = cv2.imread(r'your_file_name.jpg')\n",
        "        # img_bytes = file.read()\n",
        "        download_and_append_encodings()\n",
        "        result=FaceMain(image_file)\n",
        "\n",
        "        if(not result):\n",
        "            response = make_response(jsonify({'message': \"Could not detect your face.\"}), 400)\n",
        "            return response\n",
        "\n",
        "        object_data = json.loads(str(result['name']))\n",
        "        # Access the values in the dictionary\n",
        "        name = object_data['name']\n",
        "        student_id = object_data['student_id']\n",
        "        Attendance.create_attendance(student_id)\n",
        "        return jsonify({'message': f'{name} your Attendance has been marked'})\n",
        "      except Exception as e:\n",
        "        response = make_response(jsonify({'message': str(e)}), 400)\n",
        "        return response\n",
        "\n",
        "\n",
        "@app.route('/webGpt', methods=['POST'])\n",
        "def qaFromWeb():\n",
        "  try:\n",
        "      question = request.form['question']\n",
        "      answer = askBot(question)\n",
        "      if answer=='apply date model':\n",
        "        try:\n",
        "          result=get_current_date()\n",
        "          return jsonify({'answer': result})\n",
        "        except:\n",
        "          response = make_response(jsonify({'message': \"could not get date something bad happend\"}))\n",
        "          return response      \n",
        "      elif answer==\"apply weather model\":\n",
        "        try:\n",
        "          api_key = \"put-your-own-open-weather-api-key\"\n",
        "          city_name = \"Lahore\"\n",
        "          weather_info = get_weather(city_name, api_key)\n",
        "          return jsonify({\"weather\": weather_info})\n",
        "        except:\n",
        "          response = make_response(jsonify({'message': \"could not get date something bad happend\"}), 400)\n",
        "          return response\n",
        "  \n",
        "      elif answer==\"apply time model\":\n",
        "        try:\n",
        "          result=  get_current_time()\n",
        "          return jsonify({'answer': result})\n",
        "        except:\n",
        "          response = make_response(jsonify({'message': \"could not get date something bad happend\"}))\n",
        "          return response\n",
        "      elif answer == \"apply name model\" :\n",
        "        response = make_response(jsonify({'answer': \"I'm sorry, but as an AI language model, I don't have access to personal information like name\"}))\n",
        "        return response\n",
        "      elif answer==\"apply age model\":\n",
        "        response = make_response(jsonify({'answer': \"I'm sorry, but as an AI language model, I don't have access to personal information like age\"}))\n",
        "        return response\n",
        "      elif answer==\"apply gender model\":\n",
        "        response = make_response(jsonify({'answer': \"I'm sorry, but as an AI language model, I don't have access to personal information like gender\"}))\n",
        "        return response\n",
        "      \n",
        "      elif answer==\"apply emotion model\":\n",
        "        response = make_response(jsonify({'answer': \"I'm sorry, but as an AI language model, I don't have access to personal information like emotion\"}))\n",
        "        return response\n",
        "\n",
        "      elif answer==\"apply race model\":\n",
        "        response = make_response(jsonify({'answer': \"I'm sorry, but as an AI language model, I don't have access to personal information like race\"}))\n",
        "        return response\n",
        "\n",
        "      elif answer==\"apply attendance model\":\n",
        "        response = make_response(jsonify({'answer': \"I'm sorry, but as an AI language model, I don't have access to personal information like face\"}))\n",
        "        return response\n",
        "\n",
        "      elif answer==\"apply eye model\":\n",
        "        response = make_response(jsonify({'answer': \"I'm sorry, but as an AI language model, I don't have access to personal information like eye\"}))\n",
        "        return response\n",
        "      elif not answer:\n",
        "        try:\n",
        "          result=askQuestion(question)\n",
        "          # Destructure the dictionary\n",
        "          question, answer, score = result['question'], result['answer'], result['score']\n",
        "          return jsonify({'answer': answer,'score':score})\n",
        "        except Exception as e:\n",
        "          response = make_response(jsonify({'message': str(e)}))\n",
        "          return response\n",
        "      else:\n",
        "        return jsonify({'answer': answer})\n",
        "  except:\n",
        "    response = make_response(jsonify({'message': \"could not get answer something bad happend\"}), 400)\n",
        "    return response\n",
        "\n",
        "@app.route('/suhaBot', methods=['POST'])\n",
        "def qaFromSuha():\n",
        "  try:\n",
        "      question = request.form['question']\n",
        "      answer = askBot(question)\n",
        "      if answer=='apply date model':\n",
        "        try:\n",
        "          result=get_current_date()\n",
        "          return jsonify({'answer': result})\n",
        "        except:\n",
        "          response = make_response(jsonify({'message': \"could not get date something bad happend\"}))\n",
        "          return response      \n",
        "      elif answer==\"apply weather model\":\n",
        "        try:\n",
        "          api_key = \"put-your-own-open-weather-api-key\"\n",
        "          city_name = \"Lahore\"\n",
        "          weather_info = get_weather(city_name, api_key)\n",
        "          return jsonify({\"answer\": weather_info})\n",
        "        except:\n",
        "          response = make_response(jsonify({'message': \"could not get date something bad happend\"}), 400)\n",
        "          return response\n",
        "  \n",
        "      elif answer==\"apply time model\":\n",
        "        try:\n",
        "          result=  get_current_time()\n",
        "          return jsonify({'answer': result})\n",
        "        except:\n",
        "          response = make_response(jsonify({'message': \"could not get date something bad happend\"}))\n",
        "          return response\n",
        "          \n",
        "      elif answer == \"apply name model\" :\n",
        "        try:\n",
        "          file = request.files['file']\n",
        "          file.save(\"your_file_name.jpg\")\n",
        "          image_file = cv2.imread(r'your_file_name.jpg')\n",
        "          download_and_append_encodings()\n",
        "          result=FaceMain(image_file)\n",
        "          if(not result):\n",
        "              response = make_response(jsonify({'message': \"We do not know each other\"}), 400)\n",
        "              return response\n",
        "          object_data = json.loads(str(result['name']))\n",
        "          # Access the values in the dictionary\n",
        "          name = object_data['name']\n",
        "          response = make_response(jsonify({'answer': f\"We know each other your name is {name}.\"}))\n",
        "          return response\n",
        "        except Exception as e:\n",
        "          response = make_response(jsonify({'message': str(e)}), 400)\n",
        "          return response        \n",
        "\n",
        "      elif answer==\"apply age model\":\n",
        "        try:\n",
        "          file = request.files['file']\n",
        "          file.save(\"your_file_name.jpg\")\n",
        "          image_file = cv2.imread(r'your_file_name.jpg')\n",
        "          download_and_append_encodings()\n",
        "          result=FaceMain(image_file)\n",
        "          if(not result):\n",
        "              response = make_response(jsonify({'message': \"Could not detect your face\"}), 400)\n",
        "              return response\n",
        "          object_data = json.loads(str(result['name']))\n",
        "          # Access the values in the dictionary\n",
        "          name = object_data['name']\n",
        "          age=result['age']\n",
        "          response =make_response(jsonify({'answer': f'Looks like you are {age} Years old'}))\n",
        "          return response\n",
        "        except Exception as e:\n",
        "          response = make_response(jsonify({'message': str(e)}), 400)\n",
        "          return response        \n",
        "\n",
        "      elif answer==\"apply gender model\":\n",
        "        try:\n",
        "          file = request.files['file']\n",
        "          file.save(\"your_file_name.jpg\")\n",
        "          image_file = cv2.imread(r'your_file_name.jpg')\n",
        "          download_and_append_encodings()\n",
        "          result=FaceMain(image_file)\n",
        "          if(not result):\n",
        "              response = make_response(jsonify({'message': \"Could not detect your face\"}), 400)\n",
        "              return response\n",
        "          object_data = json.loads(str(result['name']))\n",
        "          # Access the values in the dictionary\n",
        "          name = object_data['name']\n",
        "          gender=result['gender']\n",
        "          genderToReturn=\"Female\"\n",
        "          if gender== 1:\n",
        "            genderToReturn=\"Male\"\n",
        "          response =make_response(jsonify({'answer': f'You are {genderToReturn}'}))\n",
        "          return response\n",
        "        except Exception as e:\n",
        "          response = make_response(jsonify({'message': str(e)}), 400)\n",
        "          return response        \n",
        "      \n",
        "      elif answer==\"apply emotion model\":\n",
        "        try:\n",
        "          file = request.files['file']\n",
        "          file.save(\"your_file_name.jpg\")\n",
        "          result=getEmotion()\n",
        "          response =make_response(jsonify({'answer': f'your gaze looks like you are {result}'}))\n",
        "          return response\n",
        "        except Exception as e:\n",
        "          response = make_response(jsonify({'message': str(e)}), 400)\n",
        "          return response\n",
        "\n",
        "      elif answer==\"apply race model\":\n",
        "        try:\n",
        "          file = request.files['file']\n",
        "          file.save(\"your_file_name.jpg\")\n",
        "          result=getRace()\n",
        "          response =make_response(jsonify({'answer': f'Looks like you are {result}'}))\n",
        "          return response\n",
        "        except Exception as e:\n",
        "          response = make_response(jsonify({'message': str(e)}), 400)\n",
        "          return response\n",
        "\n",
        "      elif answer==\"apply attendance model\":\n",
        "        try:\n",
        "          file = request.files['file']\n",
        "          file.save(\"your_file_name.jpg\")\n",
        "          image_file = cv2.imread(r'your_file_name.jpg')\n",
        "          download_and_append_encodings()\n",
        "          result=FaceMain(image_file)\n",
        "\n",
        "          if(not result):\n",
        "              response = make_response(jsonify({'message': \"Could not detect your face.\"}), 400)\n",
        "              return response\n",
        "\n",
        "          object_data = json.loads(str(result['name']))\n",
        "          # Access the values in the dictionary\n",
        "          name = object_data['name']\n",
        "          student_id = object_data['student_id']\n",
        "          Attendance.create_attendance(student_id)\n",
        "          return jsonify({'answer': f'{name} your Attendance has been marked'})\n",
        "        except Exception as e:\n",
        "          response = make_response(jsonify({'message': str(e)}), 400)\n",
        "          return response\n",
        "\n",
        "\n",
        "      elif answer==\"apply eye model\":\n",
        "        try:\n",
        "          file = request.files['file']\n",
        "          result=eyeMain()\n",
        "          if(not result):\n",
        "              response = make_response(jsonify({'message': \"Could not detect eyes\"}), 400)\n",
        "              return response\n",
        "          left_eye = result[\"left\"]\n",
        "          right_eye = result[\"right\"]\n",
        "          left_eye_speak = \"opened\" if left_eye == \"yes\" else \"closed\"\n",
        "          right_eye_speak = \"opened\" if right_eye == \"yes\" else \"closed\"          \n",
        "          response =make_response(jsonify({'answer': f'\"Your left eye is {left_eye_speak} and Your Right eye is {right_eye_speak} .\"'}))\n",
        "          return response\n",
        "\n",
        "        except Exception as e:\n",
        "          response = make_response(jsonify({'message': str(e)}), 400)\n",
        "          return response\n",
        "      elif not answer:\n",
        "        try:\n",
        "          result=askQuestion(question)\n",
        "          # Destructure the dictionary\n",
        "          question, answer, score = result['question'], result['answer'], result['score']\n",
        "          return jsonify({'answer': answer,'score':score})\n",
        "        except Exception as e:\n",
        "          response = make_response(jsonify({'message': str(e)}))\n",
        "          return response\n",
        "      else:\n",
        "        return jsonify({'answer': answer})\n",
        "  except:\n",
        "    response = make_response(jsonify({'message': \"could not get answer something bad happend\"}), 400)\n",
        "    return response\n",
        "\n",
        "\n",
        "def run_flask_app():\n",
        "    app.run(port=5002)  # Replace with your desired port number\n",
        "\n",
        "# Start the Flask application in a separate thread\n",
        "flask_thread = Thread(target=run_flask_app)\n",
        "flask_thread.start()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uhva7LroZifT",
        "outputId": "4211786e-d274-40b7-9fc9-3db4486040ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/May/2023 05:12:49] \"POST /studentAttendance HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'message': 'Ahmed Hassan your Attendance has been marked'}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url = 'http://localhost:5002/studentAttendance'  # Replace with your Flask app URL\n",
        "payload = {'question': \"what is ?\"}\n",
        "# Open the image file\n",
        "with open('your_file_name.jpg', 'rb') as file:\n",
        "    # Send a POST request with the file as multipart form data\n",
        "    response = requests.post(url,data=payload, files={'file': file})\n",
        "# response = requests.post(url, data=payload)\n",
        "# Check the response\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    print(data)\n",
        "else:\n",
        "    print(f\"Request failed with status code: {response.json()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AkFUsXD8n8hH",
        "outputId": "7482591c-8b5b-4dac-e309-a8e7176600dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m[05-23|05:12:49] no configuration paths supplied \n",
            "\u001b[32mINFO\u001b[0m[05-23|05:12:49] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[05-23|05:12:49] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n",
            "t=2023-05-23T05:12:49+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "t=2023-05-23T05:12:49+0000 lvl=info msg=\"client session established\" obj=tunnels.session obj=csess id=8a42acc4519b\n",
            "t=2023-05-23T05:12:49+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2023-05-23T05:12:49+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:5002 url=https://c482-34-32-211-192.ngrok-free.app\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/May/2023 05:25:17] \"OPTIONS /webGpt HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t=2023-05-23T05:25:17+0000 lvl=info msg=\"join connections\" obj=join id=18cbb6fb39fd l=127.0.0.1:5002 r=223.123.46.164:5732\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "[4.4392175e-03 1.3617949e-03 1.5415341e-02 1.0139704e-02 4.5269150e-02\n",
            " 1.7727184e-03 3.8575295e-02 3.7303595e-03 3.1855813e-01 2.9444168e-04\n",
            " 1.7410979e-03 1.0623328e-03 3.8908686e-02 4.2379410e-03 4.5149531e-03\n",
            " 1.6621668e-03 6.5770693e-02 2.6355882e-03 7.0929909e-03 2.2658186e-02\n",
            " 1.3936204e-03 5.3968523e-03 3.6525518e-02 1.4794647e-05 4.9261484e-02\n",
            " 3.2373238e-03 2.3671277e-03 8.1434650e-03 2.6128518e-03 1.1795074e-03\n",
            " 2.4922567e-03 2.2673702e-03 2.5812178e-03 1.1032979e-03 6.8031080e-02\n",
            " 2.7706096e-04 1.6035747e-03 1.1106090e-03 3.0795410e-02 3.0801653e-05\n",
            " 2.8945706e-03 1.1647121e-03 4.7898509e-02 8.2053123e-03 1.5746489e-02\n",
            " 1.0859592e-01 5.2284594e-03]\n",
            "t=2023-05-23T05:25:17+0000 lvl=info msg=\"join connections\" obj=join id=0a79e877894d l=127.0.0.1:5002 r=223.123.46.164:5732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/May/2023 05:25:19] \"POST /webGpt HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/May/2023 05:27:35] \"OPTIONS /webGpt HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t=2023-05-23T05:27:35+0000 lvl=info msg=\"join connections\" obj=join id=6fc16338e0b9 l=127.0.0.1:5002 r=223.123.46.164:5732\n",
            "t=2023-05-23T05:27:36+0000 lvl=info msg=\"join connections\" obj=join id=5138a27f269b l=127.0.0.1:5002 r=223.123.46.164:5732\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "[4.4392175e-03 1.3617949e-03 1.5415341e-02 1.0139704e-02 4.5269150e-02\n",
            " 1.7727184e-03 3.8575295e-02 3.7303595e-03 3.1855813e-01 2.9444168e-04\n",
            " 1.7410979e-03 1.0623328e-03 3.8908686e-02 4.2379410e-03 4.5149531e-03\n",
            " 1.6621668e-03 6.5770693e-02 2.6355882e-03 7.0929909e-03 2.2658186e-02\n",
            " 1.3936204e-03 5.3968523e-03 3.6525518e-02 1.4794647e-05 4.9261484e-02\n",
            " 3.2373238e-03 2.3671277e-03 8.1434650e-03 2.6128518e-03 1.1795074e-03\n",
            " 2.4922567e-03 2.2673702e-03 2.5812178e-03 1.1032979e-03 6.8031080e-02\n",
            " 2.7706096e-04 1.6035747e-03 1.1106090e-03 3.0795410e-02 3.0801653e-05\n",
            " 2.8945706e-03 1.1647121e-03 4.7898509e-02 8.2053123e-03 1.5746489e-02\n",
            " 1.0859592e-01 5.2284594e-03]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/May/2023 05:27:37] \"POST /webGpt HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/May/2023 05:27:47] \"OPTIONS /webGpt HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t=2023-05-23T05:27:47+0000 lvl=info msg=\"join connections\" obj=join id=ab54beaa38d8 l=127.0.0.1:5002 r=223.123.46.164:5732\n",
            "t=2023-05-23T05:27:47+0000 lvl=info msg=\"join connections\" obj=join id=31bf11b1bc53 l=127.0.0.1:5002 r=223.123.46.164:5732\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "[4.4392175e-03 1.3617949e-03 1.5415341e-02 1.0139704e-02 4.5269150e-02\n",
            " 1.7727184e-03 3.8575295e-02 3.7303595e-03 3.1855813e-01 2.9444168e-04\n",
            " 1.7410979e-03 1.0623328e-03 3.8908686e-02 4.2379410e-03 4.5149531e-03\n",
            " 1.6621668e-03 6.5770693e-02 2.6355882e-03 7.0929909e-03 2.2658186e-02\n",
            " 1.3936204e-03 5.3968523e-03 3.6525518e-02 1.4794647e-05 4.9261484e-02\n",
            " 3.2373238e-03 2.3671277e-03 8.1434650e-03 2.6128518e-03 1.1795074e-03\n",
            " 2.4922567e-03 2.2673702e-03 2.5812178e-03 1.1032979e-03 6.8031080e-02\n",
            " 2.7706096e-04 1.6035747e-03 1.1106090e-03 3.0795410e-02 3.0801653e-05\n",
            " 2.8945706e-03 1.1647121e-03 4.7898509e-02 8.2053123e-03 1.5746489e-02\n",
            " 1.0859592e-01 5.2284594e-03]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/May/2023 05:27:52] \"POST /webGpt HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/May/2023 05:28:09] \"OPTIONS /webGpt HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t=2023-05-23T05:28:09+0000 lvl=info msg=\"join connections\" obj=join id=08335e0e7f86 l=127.0.0.1:5002 r=223.123.46.164:5732\n",
            "t=2023-05-23T05:28:10+0000 lvl=info msg=\"join connections\" obj=join id=5a4148d5e89d l=127.0.0.1:5002 r=223.123.46.164:5732\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "[4.4392175e-03 1.3617949e-03 1.5415341e-02 1.0139704e-02 4.5269150e-02\n",
            " 1.7727184e-03 3.8575295e-02 3.7303595e-03 3.1855813e-01 2.9444168e-04\n",
            " 1.7410979e-03 1.0623328e-03 3.8908686e-02 4.2379410e-03 4.5149531e-03\n",
            " 1.6621668e-03 6.5770693e-02 2.6355882e-03 7.0929909e-03 2.2658186e-02\n",
            " 1.3936204e-03 5.3968523e-03 3.6525518e-02 1.4794647e-05 4.9261484e-02\n",
            " 3.2373238e-03 2.3671277e-03 8.1434650e-03 2.6128518e-03 1.1795074e-03\n",
            " 2.4922567e-03 2.2673702e-03 2.5812178e-03 1.1032979e-03 6.8031080e-02\n",
            " 2.7706096e-04 1.6035747e-03 1.1106090e-03 3.0795410e-02 3.0801653e-05\n",
            " 2.8945706e-03 1.1647121e-03 4.7898509e-02 8.2053123e-03 1.5746489e-02\n",
            " 1.0859592e-01 5.2284594e-03]\n",
            "t=2023-05-23T05:28:12+0000 lvl=info msg=\"join connections\" obj=join id=0c08663d0aca l=127.0.0.1:5002 r=223.123.46.164:5732\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "[4.4392175e-03 1.3617949e-03 1.5415341e-02 1.0139704e-02 4.5269150e-02\n",
            " 1.7727184e-03 3.8575295e-02 3.7303595e-03 3.1855813e-01 2.9444168e-04\n",
            " 1.7410979e-03 1.0623328e-03 3.8908686e-02 4.2379410e-03 4.5149531e-03\n",
            " 1.6621668e-03 6.5770693e-02 2.6355882e-03 7.0929909e-03 2.2658186e-02\n",
            " 1.3936204e-03 5.3968523e-03 3.6525518e-02 1.4794647e-05 4.9261484e-02\n",
            " 3.2373238e-03 2.3671277e-03 8.1434650e-03 2.6128518e-03 1.1795074e-03\n",
            " 2.4922567e-03 2.2673702e-03 2.5812178e-03 1.1032979e-03 6.8031080e-02\n",
            " 2.7706096e-04 1.6035747e-03 1.1106090e-03 3.0795410e-02 3.0801653e-05\n",
            " 2.8945706e-03 1.1647121e-03 4.7898509e-02 8.2053123e-03 1.5746489e-02\n",
            " 1.0859592e-01 5.2284594e-03]\n",
            "t=2023-05-23T05:28:14+0000 lvl=info msg=\"join connections\" obj=join id=43f4b7915cf3 l=127.0.0.1:5002 r=223.123.46.164:5732\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[4.4392175e-03 1.3617949e-03 1.5415341e-02 1.0139704e-02 4.5269150e-02\n",
            " 1.7727184e-03 3.8575295e-02 3.7303595e-03 3.1855813e-01 2.9444168e-04\n",
            " 1.7410979e-03 1.0623328e-03 3.8908686e-02 4.2379410e-03 4.5149531e-03\n",
            " 1.6621668e-03 6.5770693e-02 2.6355882e-03 7.0929909e-03 2.2658186e-02\n",
            " 1.3936204e-03 5.3968523e-03 3.6525518e-02 1.4794647e-05 4.9261484e-02\n",
            " 3.2373238e-03 2.3671277e-03 8.1434650e-03 2.6128518e-03 1.1795074e-03\n",
            " 2.4922567e-03 2.2673702e-03 2.5812178e-03 1.1032979e-03 6.8031080e-02\n",
            " 2.7706096e-04 1.6035747e-03 1.1106090e-03 3.0795410e-02 3.0801653e-05\n",
            " 2.8945706e-03 1.1647121e-03 4.7898509e-02 8.2053123e-03 1.5746489e-02\n",
            " 1.0859592e-01 5.2284594e-03]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/May/2023 05:28:17] \"POST /webGpt HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/May/2023 05:28:22] \"POST /webGpt HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/May/2023 05:28:23] \"POST /webGpt HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/May/2023 06:03:02] \"OPTIONS /webGpt HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t=2023-05-23T06:03:02+0000 lvl=info msg=\"join connections\" obj=join id=c5db55199892 l=127.0.0.1:5002 r=223.123.46.164:5644\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "[4.4392175e-03 1.3617949e-03 1.5415341e-02 1.0139704e-02 4.5269150e-02\n",
            " 1.7727184e-03 3.8575295e-02 3.7303595e-03 3.1855813e-01 2.9444168e-04\n",
            " 1.7410979e-03 1.0623328e-03 3.8908686e-02 4.2379410e-03 4.5149531e-03\n",
            " 1.6621668e-03 6.5770693e-02 2.6355882e-03 7.0929909e-03 2.2658186e-02\n",
            " 1.3936204e-03 5.3968523e-03 3.6525518e-02 1.4794647e-05 4.9261484e-02\n",
            " 3.2373238e-03 2.3671277e-03 8.1434650e-03 2.6128518e-03 1.1795074e-03\n",
            " 2.4922567e-03 2.2673702e-03 2.5812178e-03 1.1032979e-03 6.8031080e-02\n",
            " 2.7706096e-04 1.6035747e-03 1.1106090e-03 3.0795410e-02 3.0801653e-05\n",
            " 2.8945706e-03 1.1647121e-03 4.7898509e-02 8.2053123e-03 1.5746489e-02\n",
            " 1.0859592e-01 5.2284594e-03]\n",
            "t=2023-05-23T06:03:03+0000 lvl=info msg=\"join connections\" obj=join id=625927872b6d l=127.0.0.1:5002 r=223.123.46.164:5644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/May/2023 06:03:05] \"POST /webGpt HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "!ngrok http 5002 --log=stdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC1E01vkRBpO"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wbw18uLZ6NKP"
      },
      "source": [
        "## **Open new Colab Window and run the following blocks**\n",
        "\n",
        "1. Get our test image.\n",
        "```\n",
        "!wget https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/bird.jpg\n",
        "```\n",
        "\n",
        "2. Send our API Post Requests. Replace the URL below with the NGROK URL above.\n",
        "```\n",
        "import requests\n",
        "resp = requests.post(\"http://xxxxxxxxxxxx.ngrok.io/predict\",\n",
        "                     files={\"file\": open('bird.jpg','rb')})\n",
        "print(resp.json())\n",
        "```\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "063f1cad4e6f41acb45af775e7abe88b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a071d8b5cff4d459793b8cdd038f1b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a1ffcb91f8449d5b00637abf3fc8e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e65c942399b44e9b46a10ba9d12e0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17f0473d2d37415cbf6be75c7af752dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f7e100890c84a628a18e1891a5f9ceb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fb812361e814897b94a7a4475ca0df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2791097a73f74adbad48430a68ba6537": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dedb09ab77d14ed09a3ff5ca5d7a1a09",
            "placeholder": "​",
            "style": "IPY_MODEL_6889df0f2f7545008c5a74856b5b81e2",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "29a661326dde484a87f0aed0c32fd4ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e40696d889040419e8dec183bf025f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e96cfced06b4f04a6e1068abfbd9224": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d520fa104a314a38bd62800768197d2d",
            "max": 1625557313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4280afaa1675442abb9e8c56bdb76a7f",
            "value": 1625557313
          }
        },
        "32d9a503640b4ae8b31981515f511c20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35268d0559da479ab9cabc1fb0d1fa23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f7e100890c84a628a18e1891a5f9ceb",
            "placeholder": "​",
            "style": "IPY_MODEL_55a80a8189c34bcc802e0c8a7502553f",
            "value": "Writing Documents: "
          }
        },
        "35a96613170b4b27892d4e11587cfadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3d8c21d96374476ba014cffc7d12083",
            "placeholder": "​",
            "style": "IPY_MODEL_5ccb723f0bfe4cec80b3a9a30c46bcd6",
            "value": " 456k/456k [00:00&lt;00:00, 27.5MB/s]"
          }
        },
        "3941b5d23f8446c7b2270fa94ff35972": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f8c320f64fc4ab49039ebf4b05ff6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebdbf0bda0a449efa1b8e25e5a6c2e24",
            "placeholder": "​",
            "style": "IPY_MODEL_7d127733685f4e809c20d173e8a33410",
            "value": "Documents Processed: "
          }
        },
        "41c4c4e4174e4b71a6894a8b7a0eddcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4280afaa1675442abb9e8c56bdb76a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44f9b6e1e6784f3397c0ae921d4b5af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4603e6d588084a3ba0c9c1af22c3731a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a38eb5f11b54fb08833fb87840f0dfa",
            "placeholder": "​",
            "style": "IPY_MODEL_edfbb8f74e6d4084845cb2e3bb2c08e1",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "4902b799f8ac42d5b46331dd42fa4c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ae7b404d2f04a11aff8546192b10b17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc74ab0946f40a59b59509ac8687ce8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e7165cf02d349a8b73bd3f03a9533ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "546a7ce8676e4e0e84029089167ce9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f5b52393f524682a4f4fdbdd8ede356",
            "placeholder": "​",
            "style": "IPY_MODEL_f7ec2b971ea040bc970f81caffcc94df",
            "value": " 560/576 [00:10&lt;00:00, 79.48 Docs/s]"
          }
        },
        "54f51eb21f6d4984b7796dd98a32062c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e7165cf02d349a8b73bd3f03a9533ec",
            "placeholder": "​",
            "style": "IPY_MODEL_cea05cffda68456a9159f02d1701f921",
            "value": " 1.32k/1.32k [00:00&lt;00:00, 106kB/s]"
          }
        },
        "555a238bf9ca46038d7d01a46330807c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_835ff760a312493e9221d4064596ee73",
            "placeholder": "​",
            "style": "IPY_MODEL_2e40696d889040419e8dec183bf025f2",
            "value": " 1.63G/1.63G [00:39&lt;00:00, 42.3MB/s]"
          }
        },
        "55a80a8189c34bcc802e0c8a7502553f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58882b9aef7d4201a8beec736d95d78c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dce37c572274cfba86ea43d764140f7",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8237db6fd63485d9081e1a40e60388b",
            "value": 456318
          }
        },
        "5a3d878701bb495aaca15abf55796219": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bc74ab0946f40a59b59509ac8687ce8",
            "max": 27,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88ef52bc389b4663a4d921992e1de9e7",
            "value": 27
          }
        },
        "5ccb723f0bfe4cec80b3a9a30c46bcd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d17f4218dea4dcc9a48003bccafbad5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61acccd4965d4107baddacd81663d2a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a52cdc676a4d698b6e28aed5fc9d6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6889df0f2f7545008c5a74856b5b81e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b9b36b8a51c46d8b3c98b12d4d827cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a35741a09a85457ab57ad42200907ece",
            "placeholder": "​",
            "style": "IPY_MODEL_dab737d05f944c8ab1657dbb9a35c1f5",
            "value": " 27.0/27.0 [00:00&lt;00:00, 2.43kB/s]"
          }
        },
        "6cba0dba212f4f58b139fab291c1e875": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "6e96d355eeb8421bb1d516ddcdc1a30e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f5b52393f524682a4f4fdbdd8ede356": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78478664442d488485341a87f8bdd4f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7903bcb0423f4894a881a813d04cb4b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79d5473b43924c7ea3713039c1eb7cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ae7b404d2f04a11aff8546192b10b17",
            "placeholder": "​",
            "style": "IPY_MODEL_996f8996b20541838aec6a12dcfa1573",
            "value": " 899k/899k [00:00&lt;00:00, 2.81MB/s]"
          }
        },
        "7a387068e6d04aa899d7ab8bbfb79e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a38eb5f11b54fb08833fb87840f0dfa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d127733685f4e809c20d173e8a33410": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e6ea5b7071e44559dd28c553933836e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80629454eda5411dba33eae220deb9eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df4418e5b5ef4003b5de0517dedfa161",
            "placeholder": "​",
            "style": "IPY_MODEL_ea5b1f86c869400abbe8f4db65878108",
            "value": "Create embeddings:  97%"
          }
        },
        "835ff760a312493e9221d4064596ee73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "866e321690cc4a1db87471fb59c8f7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2791097a73f74adbad48430a68ba6537",
              "IPY_MODEL_90846d764ff8491bbc1dd32728b83da3",
              "IPY_MODEL_fed03caec5ae4f2eab913516dc75d5e8"
            ],
            "layout": "IPY_MODEL_0a071d8b5cff4d459793b8cdd038f1b2"
          }
        },
        "873d627546e94c9ca1e013e63f92e82e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87d0d70f1771484180ac07b4f195beb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7903bcb0423f4894a881a813d04cb4b7",
            "max": 564,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab47b32b6ffd48e7afbf66f8d2688454",
            "value": 564
          }
        },
        "88ef52bc389b4663a4d921992e1de9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8dce37c572274cfba86ea43d764140f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8faa307374634a07b11134ac192e7f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90846d764ff8491bbc1dd32728b83da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce96f56cf5b149b9b705ad833a2e4103",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4eacc04fb1749c8a88ea99a4abd207f",
            "value": 1355863
          }
        },
        "933301643614489491049a7321c1f21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e6ea5b7071e44559dd28c553933836e",
            "max": 562,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41c4c4e4174e4b71a6894a8b7a0eddcc",
            "value": 562
          }
        },
        "9427d2ec3a0f4df78ae53faf136a0590": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78478664442d488485341a87f8bdd4f7",
            "placeholder": "​",
            "style": "IPY_MODEL_44f9b6e1e6784f3397c0ae921d4b5af4",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "9674f85bbae1480d9c2dfd40d797a161": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e603dadd4f66415e9c24edeaf148d456",
            "placeholder": "​",
            "style": "IPY_MODEL_c44b9995109f42d784944f5029d41c6e",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "996f8996b20541838aec6a12dcfa1573": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a35741a09a85457ab57ad42200907ece": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a42dd6abccc6401cbda13fd7f9c352f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b04e7275f83349eb94fd43c903fbed69",
              "IPY_MODEL_ea240d452bd74dc7932c1d247cfc05ab",
              "IPY_MODEL_54f51eb21f6d4984b7796dd98a32062c"
            ],
            "layout": "IPY_MODEL_873d627546e94c9ca1e013e63f92e82e"
          }
        },
        "a52517c186f44c72ab90837426998f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9427d2ec3a0f4df78ae53faf136a0590",
              "IPY_MODEL_2e96cfced06b4f04a6e1068abfbd9224",
              "IPY_MODEL_555a238bf9ca46038d7d01a46330807c"
            ],
            "layout": "IPY_MODEL_5d17f4218dea4dcc9a48003bccafbad5"
          }
        },
        "a6ae71ac51fb4039bdf14a180b2428f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a80e4ea3e02e415b949dec98491752c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80629454eda5411dba33eae220deb9eb",
              "IPY_MODEL_e99c71c0d8f44d0883e5ce7163265c6e",
              "IPY_MODEL_546a7ce8676e4e0e84029089167ce9ed"
            ],
            "layout": "IPY_MODEL_6cba0dba212f4f58b139fab291c1e875"
          }
        },
        "a8237db6fd63485d9081e1a40e60388b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab47b32b6ffd48e7afbf66f8d2688454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad032d4c642f46c2af198a437fcf4901": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae43785c32ed4ad0be76d48069617525": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aecc5fac105d48fe8e6584e6bcaa88d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed395de1fee4511b1ce9658ff81a3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af2a61df681f4178a73b3ba581fcd7cb",
              "IPY_MODEL_58882b9aef7d4201a8beec736d95d78c",
              "IPY_MODEL_35a96613170b4b27892d4e11587cfadc"
            ],
            "layout": "IPY_MODEL_aecc5fac105d48fe8e6584e6bcaa88d3"
          }
        },
        "af2a61df681f4178a73b3ba581fcd7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63a52cdc676a4d698b6e28aed5fc9d6f",
            "placeholder": "​",
            "style": "IPY_MODEL_3941b5d23f8446c7b2270fa94ff35972",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "b04e7275f83349eb94fd43c903fbed69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae43785c32ed4ad0be76d48069617525",
            "placeholder": "​",
            "style": "IPY_MODEL_0e65c942399b44e9b46a10ba9d12e0e7",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "b1a0da4373714e38b2cb5c8c8f661234": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4902b799f8ac42d5b46331dd42fa4c8e",
            "placeholder": "​",
            "style": "IPY_MODEL_e078f6afac6d48699389845eeda6b1f5",
            "value": " 10000/? [00:01&lt;00:00, 9097.18it/s]"
          }
        },
        "b4eacc04fb1749c8a88ea99a4abd207f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c44b9995109f42d784944f5029d41c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce89fd68cb214726bb4df4a6e6e60470": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad032d4c642f46c2af198a437fcf4901",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e24921676d484c438a1394cc901122ee",
            "value": 898823
          }
        },
        "ce96f56cf5b149b9b705ad833a2e4103": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea05cffda68456a9159f02d1701f921": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0ad2b6d0a0c4d789096e74a74464b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f8c320f64fc4ab49039ebf4b05ff6a9",
              "IPY_MODEL_933301643614489491049a7321c1f21b",
              "IPY_MODEL_ef218077ba034925820302c3ff1555a8"
            ],
            "layout": "IPY_MODEL_6e96d355eeb8421bb1d516ddcdc1a30e"
          }
        },
        "d4178e9222424938ae4ead0257dbe428": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d520fa104a314a38bd62800768197d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab737d05f944c8ab1657dbb9a35c1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dce026d29fd641238e68874e212967b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35268d0559da479ab9cabc1fb0d1fa23",
              "IPY_MODEL_87d0d70f1771484180ac07b4f195beb4",
              "IPY_MODEL_b1a0da4373714e38b2cb5c8c8f661234"
            ],
            "layout": "IPY_MODEL_29a661326dde484a87f0aed0c32fd4ef"
          }
        },
        "dedb09ab77d14ed09a3ff5ca5d7a1a09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4418e5b5ef4003b5de0517dedfa161": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e078f6afac6d48699389845eeda6b1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1660868c5724a2a83391f1b69f5a494": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9674f85bbae1480d9c2dfd40d797a161",
              "IPY_MODEL_ce89fd68cb214726bb4df4a6e6e60470",
              "IPY_MODEL_79d5473b43924c7ea3713039c1eb7cf9"
            ],
            "layout": "IPY_MODEL_17f0473d2d37415cbf6be75c7af752dc"
          }
        },
        "e24921676d484c438a1394cc901122ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3d8c21d96374476ba014cffc7d12083": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e603dadd4f66415e9c24edeaf148d456": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e99c71c0d8f44d0883e5ce7163265c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61acccd4965d4107baddacd81663d2a9",
            "max": 576,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6ae71ac51fb4039bdf14a180b2428f0",
            "value": 576
          }
        },
        "ea240d452bd74dc7932c1d247cfc05ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8faa307374634a07b11134ac192e7f6d",
            "max": 1321,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fb812361e814897b94a7a4475ca0df9",
            "value": 1321
          }
        },
        "ea5b1f86c869400abbe8f4db65878108": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebdbf0bda0a449efa1b8e25e5a6c2e24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edfbb8f74e6d4084845cb2e3bb2c08e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef218077ba034925820302c3ff1555a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4178e9222424938ae4ead0257dbe428",
            "placeholder": "​",
            "style": "IPY_MODEL_7a387068e6d04aa899d7ab8bbfb79e9d",
            "value": " 10000/? [00:10&lt;00:00, 949.97 docs/s]"
          }
        },
        "f7ec2b971ea040bc970f81caffcc94df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f97bd054fbfd4c0fad33ddc80b3d2488": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4603e6d588084a3ba0c9c1af22c3731a",
              "IPY_MODEL_5a3d878701bb495aaca15abf55796219",
              "IPY_MODEL_6b9b36b8a51c46d8b3c98b12d4d827cf"
            ],
            "layout": "IPY_MODEL_063f1cad4e6f41acb45af775e7abe88b"
          }
        },
        "fed03caec5ae4f2eab913516dc75d5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32d9a503640b4ae8b31981515f511c20",
            "placeholder": "​",
            "style": "IPY_MODEL_0a1ffcb91f8449d5b00637abf3fc8e5c",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 15.9MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
